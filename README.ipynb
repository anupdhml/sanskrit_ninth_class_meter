{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5484efe",
   "metadata": {},
   "source": [
    "# Metrical Analysis of Sanskrit Ninth Class Verb Forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed15db9",
   "metadata": {},
   "source": [
    "## Getting Verbal Roots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f8269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p downloads\n",
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922babf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O downloads/whitney_roots.pdf http://gretil.sub.uni-goettingen.de/gretil_elib/Whi885__Whitney_Roots-ACCENTED.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ee83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pdftk if not already there. eg: for ubuntu: sudo apt install pdftk\n",
    "!pdftk downloads/whitney_roots.pdf cat 229 output data/whitney_roots_ninth_class.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cfa6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces data/whitney_roots_ninth_class.txt\n",
    "!pdftotext data/whitney_roots_ninth_class.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a46f06",
   "metadata": {},
   "source": [
    "Cleanup the text version manually, fixing formatting and diacritics.\n",
    "\n",
    "One extra thing we also do is rewrite a form like _mī̆nā_ as _minā/mīnā_, i.e. re-write the variation in the root vowel as two different stem forms explicitly. This helps us visualize and process the variants easily later (note: whitney has only 3 stems here marked like this -- namely _mī̆nā_, _vlī̆nā_ and _dhū̆nī_ -- so we can get away with doing this manually here easily. If there were a lot of these, we could have automated it)\n",
    "\n",
    "Final results are in [data/whitney_roots_ninth_class_cleaned.txt](data/whitney_roots_ninth_class_cleaned.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fa5c077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try to get the 9th class forms/roots directly from Lubotksy's concordance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d50821",
   "metadata": {},
   "source": [
    "## Parsing Verbal Roots Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c836cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_HEADER = \"6. nā-class\"\n",
    "EARLIER_LANGUAGE_HEADER = \"A. Earlier Language\"\n",
    "EARLIER_AND_LATER_LANGUAGE_HEADER = \"B. Earlier and Later Language\"\n",
    "LATER_LANGUAGE_HEADER = \"C. Later Language\"\n",
    "\n",
    "NINTH_CLASS_STRONG_MARKER = \"ā\"\n",
    "NINTH_CLASS_WEAK_MARKER = \"ī\"\n",
    "\n",
    "whitney_roots = []\n",
    "\n",
    "language_period = None\n",
    "\n",
    "with open(\"data/whitney_roots_ninth_class_cleaned.txt\", 'r') as whitney_file:\n",
    "    while line := whitney_file.readline():\n",
    "        variant_no = None\n",
    "        attestation_texts = None\n",
    "        weak_only = False\n",
    "        \n",
    "        line = line.rstrip()\n",
    "        if not line or CLASS_HEADER in line:\n",
    "            continue    \n",
    "        elif EARLIER_LANGUAGE_HEADER in line:\n",
    "            language_period = \"Earlier\"\n",
    "            continue\n",
    "        elif EARLIER_AND_LATER_LANGUAGE_HEADER in line:\n",
    "            language_period = \"Earlier & Later\"\n",
    "            continue\n",
    "        elif LATER_LANGUAGE_HEADER in line:\n",
    "            language_period = \"Later\"\n",
    "            continue\n",
    "                \n",
    "        line_parts = line.split()\n",
    "        if line_parts[0].isdigit():\n",
    "            variant_no = line_parts.pop(0)\n",
    "        stem = line_parts.pop(0)\n",
    "        if line_parts:\n",
    "            attestation_texts = \" \".join(line_parts)\n",
    "        \n",
    "        # this is an assumption safe to make for our data even if there's multiple stem variants\n",
    "        if stem.endswith(NINTH_CLASS_WEAK_MARKER):\n",
    "            weak_only = True\n",
    "        \n",
    "        # if stem has a variant it will be marked '/'     \n",
    "        stem_variants = stem.split('/')\n",
    "        weak_stem_variants = []\n",
    "        strong_stem_variants = []\n",
    "        root_variants = []\n",
    "        \n",
    "        # populate all the variants above\n",
    "        for stem_variant in stem_variants:\n",
    "            # removes the last two chars\n",
    "            # at this stage, this is a guess only and may not match what is actually used\n",
    "            # in the grammars/ dictionaries\n",
    "            root_variants.append(stem_variant[:-2])\n",
    "            \n",
    "            if stem_variant.endswith(NINTH_CLASS_WEAK_MARKER):\n",
    "                weak_stem_variants.append(stem_variant)\n",
    "                strong_stem_variants.append(stem_variant[:-1] + NINTH_CLASS_STRONG_MARKER)\n",
    "            else:\n",
    "                strong_stem_variants.append(stem_variant)\n",
    "                weak_stem_variants.append(stem_variant[:-1] + NINTH_CLASS_WEAK_MARKER)\n",
    "        root_variants = sorted(list(set(root_variants)))   \n",
    "        \n",
    "        # set the final strings\n",
    "        root = ' '.join(root_variants)\n",
    "        strong_stem = ' '.join(strong_stem_variants)\n",
    "        weak_stem = ' '.join(weak_stem_variants)\n",
    "        \n",
    "        # FIXME better place to keep these?\n",
    "        if root == \"pu\":\n",
    "            root = \"pū\"\n",
    "        elif root == \"ju\":\n",
    "            root = \"jū\"\n",
    "        elif root == \"ji\":\n",
    "            root = \"jī\"\n",
    "        elif root == \"vr̥\" and variant_no == '2':\n",
    "            # variant_no 1 'cover' is attested only in AV. 2 is 'choose'\n",
    "            # FIXME set stem as variant here too and ensure both are searched for\n",
    "            # but long variant doesn't have any hits here so safe to ignore this here\n",
    "            #root = \"vr̥ ~ vr̥̄\"\n",
    "            # also if we pass it like this, we should also change the stems here\n",
    "            root = \"vr̥ vr̥̄\" # other root is vr̥(1, cover which won't match)\n",
    "        # FIXME better way to pass these exceptions\n",
    "        # modifying the root here ensures for now we only find matches for the variants\n",
    "        # used in vedaweb\n",
    "        # SrI 1 mix: yes\n",
    "        # SrI 2 boil: not (VB: SrInati..)\n",
    "        elif root == \"śrī\" and variant_no == '2': # boil\n",
    "            root = \"śrī 2\" # other root is śrī (1, mix) which WILL match\n",
    "        # aS 1 attain: not (only in mahabhharata 'aSnIs')\n",
    "        # aS 2 eat yes\n",
    "        elif root == \"aś\" and variant_no == '1': # eat\n",
    "            root = \"aśⁱ\" # other root is aś (2, attain) which won't match\n",
    "        # gR as gr̥̄ 1 \"sing\" attested \n",
    "        # gR 2 \"swallow\" not (only in AVS)\n",
    "        elif root == \"gr̥\" and variant_no == '1': # sing\n",
    "            root = \"gr̥̄ 1\" # other root is gr̥(2, swallow) which won't match\n",
    "        #elif variant_no:\n",
    "            # FIXME assign vedaweb equivalent variant numbers here?\n",
    "        #    root += ' ' + variant_no \n",
    "        \n",
    "        whitney_roots.append({\n",
    "            \"root_guess\": root, # this is really an estimated guess based on the stem \n",
    "            \"variant_no\": variant_no,\n",
    "            \"strong_stem\": strong_stem,\n",
    "            \"weak_stem\": weak_stem,\n",
    "            \"weak_only\": weak_only,\n",
    "            \"attestation_texts\": attestation_texts,\n",
    "            \"language_period\": language_period,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0093fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb1cc4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_guess</th>\n",
       "      <th>variant_no</th>\n",
       "      <th>strong_stem</th>\n",
       "      <th>weak_stem</th>\n",
       "      <th>weak_only</th>\n",
       "      <th>attestation_texts</th>\n",
       "      <th>language_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>None</td>\n",
       "      <td>inā</td>\n",
       "      <td>inī</td>\n",
       "      <td>True</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>iṣṇā</td>\n",
       "      <td>iṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ubh</td>\n",
       "      <td>None</td>\n",
       "      <td>ubhnā</td>\n",
       "      <td>ubhnī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>uṣṇā</td>\n",
       "      <td>uṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kṣi</td>\n",
       "      <td>None</td>\n",
       "      <td>kṣiṇā</td>\n",
       "      <td>kṣiṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  root_guess variant_no strong_stem weak_stem  weak_only attestation_texts  \\\n",
       "0          i       None         inā       inī       True                V.   \n",
       "1         iṣ       None        iṣṇā      iṣṇī      False              None   \n",
       "2        ubh       None       ubhnā     ubhnī      False                V.   \n",
       "3         uṣ       None        uṣṇā      uṣṇī      False                V.   \n",
       "4        kṣi       None       kṣiṇā     kṣiṇī      False              V.B.   \n",
       "\n",
       "  language_period  \n",
       "0         Earlier  \n",
       "1         Earlier  \n",
       "2         Earlier  \n",
       "3         Earlier  \n",
       "4         Earlier  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whitney_roots = pandas.DataFrame.from_dict(whitney_roots)\n",
    "df_whitney_roots.to_csv(\"data/whitney_roots_ninth_class.csv\", index=None)\n",
    "df_whitney_roots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d5a10",
   "metadata": {},
   "source": [
    "## Annotating Verbal Roots with Rig Veda Attestations (Manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b674f1f",
   "metadata": {},
   "source": [
    "Using Lubotsky's concordance, attestation info is manually added to [data/whitney_roots_ninth_class.csv](data/whitney_roots_ninth_class.csv).\n",
    "\n",
    "Final results are in [data/roots_ninth_class_manual.csv](data/roots_ninth_class_manual.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a05e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_roots_manual = pandas.read_csv(\"data/roots_ninth_class_manual.csv\")\n",
    "df_roots_manual = pandas.read_csv(\"data/roots_ninth_class_manual.csv\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35302f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root</th>\n",
       "      <th>variant_no</th>\n",
       "      <th>stem</th>\n",
       "      <th>weak_only</th>\n",
       "      <th>attestation_texts</th>\n",
       "      <th>language_period</th>\n",
       "      <th>rig_veda_weak_attestations</th>\n",
       "      <th>rig_veda_strong_attestations</th>\n",
       "      <th>lubotsky_page_no</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iṣ</td>\n",
       "      <td></td>\n",
       "      <td>iṣṇā</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Earlier</td>\n",
       "      <td></td>\n",
       "      <td>1.63.2d</td>\n",
       "      <td>1:</td>\n",
       "      <td>iSnAsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vr̥</td>\n",
       "      <td>1</td>\n",
       "      <td>vr̥ṇī</td>\n",
       "      <td>True</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>1.180.4b 1.67.1b 4.25.3a</td>\n",
       "      <td></td>\n",
       "      <td>2:1338-1339</td>\n",
       "      <td>avRNItam vRnIte vRnIte(accented - last syll)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pu</td>\n",
       "      <td></td>\n",
       "      <td>punā</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>9.16.3c 9.67.27d</td>\n",
       "      <td>1.133.1a 10.13.3d</td>\n",
       "      <td>1:900-</td>\n",
       "      <td>punIhi puNAmi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root variant_no   stem  weak_only attestation_texts  language_period  \\\n",
       "1    iṣ              iṣṇā      False                            Earlier   \n",
       "18  vr̥          1  vr̥ṇī       True                V.          Earlier   \n",
       "37   pu              punā      False                    Earlier & Later   \n",
       "\n",
       "   rig_veda_weak_attestations rig_veda_strong_attestations lubotsky_page_no  \\\n",
       "1                                                  1.63.2d               1:   \n",
       "18   1.180.4b 1.67.1b 4.25.3a                                   2:1338-1339   \n",
       "37           9.16.3c 9.67.27d            1.133.1a 10.13.3d           1:900-   \n",
       "\n",
       "                                           notes  \n",
       "1                                         iSnAsi  \n",
       "18  avRNItam vRnIte vRnIte(accented - last syll)  \n",
       "37                                 punIhi puNAmi  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO remove test df once we have all the annotations\n",
    "#df_roots_test_manual = df_roots_manual[~df_roots[\"notes\"].isna()]\n",
    "df_roots_test_manual = df_roots_manual[df_roots_manual[\"notes\"].str.len() > 0]\n",
    "df_roots_test_manual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488bf39",
   "metadata": {},
   "source": [
    "## Annotating Verbal Roots with Rig Veda Attestations (Own Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18c62a",
   "metadata": {},
   "source": [
    "### Getting Rig Veda padapatha text (Eichler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.detlef108.de/Rigveda.htm \n",
    "# http://www.detlef108.de/Notes-to-the-Rigveda-Page.htm \n",
    "!wget -O downloads/rv_padapatha_eichler.html http://www.detlef108.de/RV-Padapatha-TA3-paada-NA-UTF8.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3d5d638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt install html2text\n",
    "#!html2text -utf8 -width 3000 -o rv_padapatha.txt rv_padaptaha.html\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"downloads/rv_padapatha_eichler.html\", \"r\") as input_file:\n",
    "    soup = BeautifulSoup(input_file)\n",
    "    \n",
    "    hymns = []\n",
    "    \n",
    "    for para in soup.find_all(\"p\"):\n",
    "        # ignore the ending notes\n",
    "        if para.contents[0].name == \"span\":\n",
    "            continue\n",
    "        \n",
    "        #hymns.append(para.text.rstrip()) # no extra lines between hymns\n",
    "        hymns.append(para.text)\n",
    "    \n",
    "    with open(\"data/rv_padapatha_eichler.txt\", 'w') as f:\n",
    "        f.write(\"\".join(hymns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3fe51439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO break the padapatha verse into sub-lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477bf80",
   "metadata": {},
   "source": [
    "### Getting Rig Veda padapatha / metrically restored texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cceh/c-salt_vedaweb_sources/tree/master/rigveda/versions\n",
    "# description of the sources here:\n",
    "# https://github.com/cceh/c-salt_vedaweb_tei/blob/master/vedaweb_corpus.tei\n",
    "# https://vedaweb.uni-koeln.de/rigveda/help\n",
    "\n",
    "!wget -O downloads/rv_padapatha_lubotsky.json https://raw.githubusercontent.com/cceh/c-salt_vedaweb_sources/master/rigveda/versions/lubotsky.json\n",
    "\n",
    "!wget -O downloads/rv_samhitapatha_vnh.json https://raw.githubusercontent.com/cceh/c-salt_vedaweb_sources/master/rigveda/versions/vnh.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d590814b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote the sanskrit text to data/rv_padapatha_lubotsky.txt\r\n",
      "\r\n",
      "List of sanskrit chars resolved from the text:\r\n",
      "\r\n",
      "vowels_short: ['a', 'a\\\\', 'i', 'l̥', 'r̥', 'r̥\\\\', 'u', 'u\\\\', '~i', '~u', 'á', 'í', 'ú', 'ŕ̥']\r\n",
      "vowels_long: ['ai', 'au', 'au\\\\', 'aí', 'aú', 'e', 'e\\\\', 'o', 'o\\\\', 'r̥̄', 'r̥̄́', 'é', 'ó', 'ā', 'ā\\\\', 'ā́', 'ī', 'ī\\\\', 'ī́', 'ū', 'ū\\\\', 'ū́']\r\n",
      "consonants: ['b', 'bh', 'c', 'ch', 'd', 'dh', 'g', 'gh', 'h', 'j', 'jh', 'k', 'kh', 'l', 'm', 'm̐', 'n', 'p', 'ph', 'r', 's', 't', 'th', 'v', 'y', 'ñ', 'ś', 'ḍ', 'ḍh', 'ḥ', 'ḷ', 'ḷh', 'ṁ', 'ṅ', 'ṇ', 'ṣ', 'ṭ', 'ṭh']\r\n",
      "special_chars: [' ']\r\n",
      "others: []\r\n",
      "\r\n",
      "List of sanskrit chars missing:\r\n",
      "\r\n",
      "vowels_short: ['i\\\\', 'r̥̀', 'à', 'ì', 'ï', 'ù', 'ü']\r\n",
      "vowels_long: ['ai\\\\', 'aì', 'aù', 'è', 'ò', 'ā̀', 'ī3', 'ī̀', 'ī́3', 'ū3', 'ū̀', 'ū́3']\r\n",
      "consonants: []\r\n",
      "special_chars: [' ̀', \"'\"]\r\n"
     ]
    }
   ],
   "source": [
    "# make text version from the jsons, with line numbers at the beginning\n",
    "!python transform_json_corpus.py downloads/rv_padapatha_lubotsky.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c4805c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote the sanskrit text to data/rv_samhitapatha_vnh.txt\r\n",
      "\r\n",
      "List of sanskrit chars resolved from the text:\r\n",
      "\r\n",
      "vowels_short: ['a', 'a\\\\', 'i', 'i\\\\', 'l̥', 'r̥', 'u', '~i', '~u', 'á', 'í', 'ú', 'ŕ̥']\r\n",
      "vowels_long: ['ai', 'ai\\\\', 'au', 'aí', 'aú', 'e', 'e\\\\', 'o', 'o\\\\', 'r̥̄', 'r̥̄́', 'é', 'ó', 'ā', 'ā\\\\', 'ā́', 'ī', 'ī3', 'ī́', 'ī́3', 'ū', 'ū́']\r\n",
      "consonants: ['b', 'bh', 'c', 'ch', 'd', 'dh', 'g', 'gh', 'h', 'j', 'jh', 'k', 'kh', 'l', 'm', 'm̐', 'n', 'p', 'ph', 'r', 's', 't', 'th', 'v', 'y', 'ñ', 'ś', 'ḍ', 'ḍh', 'ḥ', 'ḷ', 'ḷh', 'ṁ', 'ṅ', 'ṇ', 'ṣ', 'ṭ', 'ṭh']\r\n",
      "special_chars: [' ', ' ̀']\r\n",
      "others: [\"'bh\", \"'d\", \"'dh\", \"'g\", \"'h\", \"'j\", \"'k\", \"'m\", \"'n\", \"'p\", \"'r\", \"'s\", \"'t\", \"'v\", \"'y\", \"'ś\"]\r\n",
      "\r\n",
      "List of sanskrit chars missing:\r\n",
      "\r\n",
      "vowels_short: ['r̥\\\\', 'r̥̀', 'u\\\\', 'à', 'ì', 'ï', 'ù', 'ü']\r\n",
      "vowels_long: ['au\\\\', 'aì', 'aù', 'è', 'ò', 'ā̀', 'ī\\\\', 'ī̀', 'ū3', 'ū\\\\', 'ū̀', 'ū́3']\r\n",
      "consonants: []\r\n",
      "special_chars: [\"'\"]\r\n"
     ]
    }
   ],
   "source": [
    "# make text version from the jsons, with line numbers at the beginning\n",
    "!python transform_json_corpus.py downloads/rv_samhitapatha_vnh.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad05b26",
   "metadata": {},
   "source": [
    "Make sure that the missing chars here are okay to ignore, or that they are just written differently in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784c815",
   "metadata": {},
   "source": [
    "### Searching text for ninth-class verbal forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "bb34ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO search text for ninth-class verbal forms , replicating vedaweb search below?\n",
    "# use vidyut to identify only finite verbal forms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439471f4",
   "metadata": {},
   "source": [
    "## Annotating Verbal Roots with Rig Veda Attestations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093bc910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 strong, 0 weak attestations\n",
      "note: using 'iṣ 1' for root guess iṣ (as done in vedaweb)\n",
      "iṣ 1: 1 strong, 0 weak attestations\n",
      "ubh: 2 strong, 0 weak attestations\n",
      "uṣ: 0 strong, 0 weak attestations\n",
      "note: using 'kṣī' for root guess kṣi (as done in vedaweb)\n",
      "kṣī: 3 strong, 0 weak attestations\n",
      "gr̥: 0 strong, 0 weak attestations\n",
      "note: using 'gr̥bhⁱ' for root guess gr̥bh (as done in vedaweb)\n",
      "gr̥bhⁱ: 10 strong, 6 weak attestations\n",
      "jū: 4 strong, 1 weak attestations\n",
      "note: using 'jyā' for root guess jī (as done in vedaweb)\n",
      "jyā: 3 strong, 0 weak attestations\n",
      "dr̥: 0 strong, 0 weak attestations\n",
      "drū: 0 strong, 0 weak attestations\n",
      "note: using 'pr̥̄ 1' for root guess pr̥ (as done in vedaweb)\n",
      "pr̥̄ 1: 12 strong, 6 weak attestations\n",
      "pruṣ: 0 strong, 0 weak attestations\n",
      "bhrī: 0 strong, 0 weak attestations\n",
      "note: using 'mī 1' for root guess mi mī (as done in vedaweb)\n",
      "mī 1: 23 strong, 2 weak attestations\n",
      "note: using 'mr̥̄ 1' for root guess mr̥ (as done in vedaweb)\n",
      "mr̥̄ 1: 0 strong, 1 weak attestations\n",
      "ram: 4 strong, 0 weak attestations\n",
      "note: using 'rī' for root guess ri (as done in vedaweb)\n",
      "rī: 20 strong, 9 weak attestations\n",
      "vr̥: 0 strong, 0 weak attestations\n",
      "vli vlī: 0 strong, 0 weak attestations\n",
      "śam: 0 strong, 0 weak attestations\n",
      "ścam: 0 strong, 0 weak attestations\n",
      "note: using 'śrathⁱ' for root guess śrath (as done in vedaweb)\n",
      "śrathⁱ: 1 strong, 1 weak attestations\n",
      "śrī: 0 strong, 5 weak attestations\n",
      "śrī 2: 0 strong, 0 weak attestations\n",
      "note: using 'sā si' for root guess si (as done in vedaweb)\n",
      "sā si: 1 strong, 1 weak attestations\n",
      "subh: 0 strong, 0 weak attestations\n",
      "note: using 'skambhⁱ' for root guess skabh (as done in vedaweb)\n",
      "skambhⁱ: 1 strong, 0 weak attestations\n",
      "spr̥: 0 strong, 0 weak attestations\n",
      "note: using 'hr̥̄' for root guess hr̥ (as done in vedaweb)\n",
      "hr̥̄: 0 strong, 4 weak attestations\n",
      "hru: 0 strong, 0 weak attestations\n",
      "aś: 0 strong, 0 weak attestations\n",
      "krī: 1 strong, 0 weak attestations\n",
      "gr̥̄ 1: 10 strong, 40 weak attestations\n",
      "grath: 0 strong, 0 weak attestations\n",
      "note: using 'gr̥hⁱ' for root guess gr̥h (as done in vedaweb)\n",
      "gr̥hⁱ: 1 strong, 0 weak attestations\n",
      "note: using 'jñā' for root guess jā (as done in vedaweb)\n",
      "jñā: 8 strong, 5 weak attestations\n",
      "pū: 6 strong, 15 weak attestations\n",
      "prī: 1 strong, 2 weak attestations\n",
      "note: using 'bandh' for root guess badh (as done in vedaweb)\n",
      "bandh: 1 strong, 0 weak attestations\n",
      "note: using 'mathⁱ' for root guess math (as done in vedaweb)\n",
      "mathⁱ: 1 strong, 0 weak attestations\n",
      "note: using 'muṣⁱ' for root guess muṣ (as done in vedaweb)\n",
      "muṣⁱ: 3 strong, 1 weak attestations\n",
      "mr̥d: 0 strong, 0 weak attestations\n",
      "lu: 0 strong, 0 weak attestations\n",
      "vr̥ vr̥̄: 0 strong, 85 weak attestations\n",
      "note: using 'śr̥̄ 1' for root guess śr̥ (as done in vedaweb)\n",
      "śr̥̄ 1: 3 strong, 6 weak attestations\n",
      "note: using 'stambhⁱ' for root guess stabh (as done in vedaweb)\n",
      "stambhⁱ: 15 strong, 0 weak attestations\n",
      "note: using 'str̥̄' for root guess str̥ (as done in vedaweb)\n",
      "str̥̄: 2 strong, 7 weak attestations\n",
      "aśⁱ: 3 strong, 1 weak attestations\n",
      "kuṣ: 0 strong, 0 weak attestations\n",
      "kliś: 0 strong, 0 weak attestations\n",
      "dhu dhū: 0 strong, 0 weak attestations\n",
      "puṣ: 0 strong, 0 weak attestations\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "#!curl -H \"Content-Type: application/json\" -XPOST https://vedaweb.uni-koeln.de/rigveda/api/search/grammar -d '{}'\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "\n",
    "VEDAWEB_API_URL = \"https://vedaweb.uni-koeln.de/rigveda/api\"\n",
    "\n",
    "def parse_vedaweb_search_highlight_text(text):\n",
    "    word_instances = []\n",
    "    \n",
    "    for instance_text in BeautifulSoup(text, \"lxml\").text.split('/'):\n",
    "        word_gloss = {}\n",
    "        for prop in instance_text.split(';'):\n",
    "            prop_parts = prop.split(':')\n",
    "            prop_name = prop_parts[0].strip()\n",
    "            prop_value = prop_parts[1].strip()\n",
    "            \n",
    "            #if prop_name in [\"lemma\", \"lemma type\"]:\n",
    "            #    continue\n",
    "                    \n",
    "            word_gloss[prop_name] = prop_value\n",
    "            \n",
    "        word_instances.append(word_gloss)\n",
    "\n",
    "    return word_instances\n",
    "        \n",
    "def search_verb_form_attestations_vedaweb_helper(root, stem=None, results_no=10, results_from=0):\n",
    "    search_block = {\n",
    "        \"lemma type\": \"root\",\n",
    "        # make sure we get verbal forms only\n",
    "        # (i.e. ignore nominal forms like participles which are not marked for person)\n",
    "        \"person\": \"*\", # is present\n",
    "        \"required\": True,\n",
    "        \"distance\": 0\n",
    "    }\n",
    "    \n",
    "    # TODO make this compulsory\n",
    "    if stem:\n",
    "        # handle stems that have spaces to mark variants too!\n",
    "        # when multiple terms are present separated via space, vedaweb interprets it as an\n",
    "        # \"or\" search which is convenient for us\n",
    "        # TODO break down the search for each variant so that we can track results for each\n",
    "        # separately? not needed at this stage though\n",
    "        stem_variants = [ '*' + stem_variant + '*' for stem_variant in stem.split(\" \")]\n",
    "        search_block[\"term\"] = ' '.join(stem_variants)\n",
    "        #print(search_block[\"term\"])\n",
    "        \n",
    "    # for these roots, actually pass in the roots to disambiguate its forms from\n",
    "    # *mi* and *muṣ*\n",
    "    # FIXME find a better place for these overrides\n",
    "    if root in [\n",
    "        # FIXME auto-figure out by subset (if the stem is a subset already pass root to disambiguate)\n",
    "        \"i\", \"uṣ\",\n",
    "        \"vr̥ vr̥̄\", \"vr̥\", \"aśⁱ\", \"aś\", \"gr̥̄ 1\", \"gr̥\",\n",
    "        \"śrī\", \"śrī 2\", # FIXME vedaweb does not actually have the second variant at all\n",
    "    ]:      \n",
    "        search_block[\"lemma\"] = root\n",
    "        #print(search_block[\"lemma\"])\n",
    "    \n",
    "    response = requests.post(\n",
    "        VEDAWEB_API_URL + \"/search/grammar\",\n",
    "        headers = {\"Content-Type\": \"application/json\"},\n",
    "        json = {\n",
    "            \"mode\": \"grammar\",\n",
    "            \"accents\": False,\n",
    "            \"blocks\": [search_block],\n",
    "            \"scopes\": [],\n",
    "            \"meta\": {\n",
    "                #\"hymnAddressee\": [],\n",
    "                #\"hymnGroup\": [],\n",
    "                #\"strata\": [],\n",
    "                #\"stanzaType\": [],\n",
    "                #\"lateAdditions\": []\n",
    "            },\n",
    "            \"size\": results_no,\n",
    "            \"from\": results_from\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # raises an exception on non-200 responses, since we want to know and act on it\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    #pprint(response.request.body)\n",
    "    #pprint(response.json()[\"hits\"][0])\n",
    "    \n",
    "    response_json = response.json()\n",
    "    \n",
    "    results = {}\n",
    "    found_lemmas = set()\n",
    "    for hit in response_json[\"hits\"]:\n",
    "        stanza_no = hit[\"docId\"]\n",
    "        \n",
    "        words = []\n",
    "        for word, highlight_text in hit[\"highlight\"].items():\n",
    "            word_instances = parse_vedaweb_search_highlight_text(highlight_text) \n",
    "            for word_gloss in word_instances:\n",
    "                lemma = word_gloss.pop(\"lemma\")\n",
    "                #lemma = word_gloss.get(\"lemma\")\n",
    "                # we don't need this since everything is root for us\n",
    "                word_gloss.pop(\"lemma type\")\n",
    "                words.append({\n",
    "                    \"word\": word,\n",
    "                    \"gloss\": word_gloss\n",
    "                })\n",
    "                found_lemmas.add(lemma)\n",
    "        \n",
    "        if stanza_no in results:\n",
    "            # shouldn't happen in our case at all, but just in case\n",
    "            raise Exception(f\"Unexpected, duplicate stanza number found: {stanza_no}\")\n",
    "        else:\n",
    "            results[stanza_no] = words\n",
    "    \n",
    "    # safeguard while testing\n",
    "    time.sleep(1)\n",
    "    return {\n",
    "        \"lemmas\": list(found_lemmas),\n",
    "        \"count\": len(results),\n",
    "        \"total\": response_json[\"total\"], \n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "# TODO remove since we don't use this anymore\n",
    "ROOT_VARIANT_SUFFIXES = [\n",
    "    # try with different order, see if we get different results?\n",
    "    # also need to try all of them?\n",
    "    # marker of seṭ roots (goes back to PIE roots ending in laryngeals)\n",
    "    #\"ⁱ\",\n",
    "    # numbers used to mark roots of same phonetic shape but different semantics \n",
    "    #\" 1\", \" 2\", \n",
    "    # try this next\n",
    "    #\" 3\",\n",
    "    # up to 3 really should be enough but just in case\n",
    "    # try with just these for roots where we don't get any hits\n",
    "    #\" 4\", \" 5\",\n",
    "    # last resort: matches anything that follows\n",
    "    # needed to catch cases like vr̥ ~ vr̥̄ in vedaweb\n",
    "    # kind of safe because we also limit our searches by stem where we specify\n",
    "    # the suffix directly following the root, but to limit false positives,\n",
    "    # we put this last and specify predicatable variants above\n",
    "    \"*\"\n",
    "]\n",
    "\n",
    "def search_verb_form_attestations_vedaweb(root, stem=None, results_no=10, results_from=0):\n",
    "    results = search_verb_form_attestations_vedaweb_helper(root, stem, results_no)\n",
    "    \n",
    "#     if results[\"count\"] == 0:\n",
    "#         for root_variant_suffix in ROOT_VARIANT_SUFFIXES:\n",
    "#             # our initial root data comes from whitney but how it's represented in vedaweb\n",
    "#             # may be different so gotta try with other variant forms\n",
    "#             root_variant = root + root_variant_suffix\n",
    "#             # useful while debugging\n",
    "#             #print(\n",
    "#             #    f\"No results found for root:{root} stem:{stem}.\",\n",
    "#             #    f\"Retrying with root variant: {root_variant}\"\n",
    "#             #)\n",
    "#             results = search_verb_form_attestations_vedaweb_helper(root_variant, stem, results_no)\n",
    "\n",
    "#             # we found a match for a working suffix so stop now\n",
    "#             if results[\"count\"] > 0:\n",
    "#                 break\n",
    "            \n",
    "            \n",
    "    # FIXME implement getting all results\n",
    "    # not needed right now since we get all results at once\n",
    "    all_results = results[\"results\"]    \n",
    "    all_results_count = len(all_results)   \n",
    "        \n",
    "    if len(results[\"lemmas\"]) > 1:\n",
    "        raise Exception(\n",
    "            f\"Unexpected, multiple roots found while searching for {root}: {results['lemmas']}\"\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"root_vedaweb\": results[\"lemmas\"][0] if (all_results_count > 0) else None,\n",
    "        \"count\": all_results_count,\n",
    "        \"total\": results[\"total\"],\n",
    "        \"results\": all_results\n",
    "    }\n",
    "        \n",
    "roots = []\n",
    "\n",
    "roots_attested_words_by_stanza = {}\n",
    "\n",
    "for root in whitney_roots:       \n",
    "    # TODO remove this test filter\n",
    "    #if root[\"root_guess\"] not in [\"iṣ 1\", \"pū\", \"vr̥~ vr̥̄\"]:\n",
    "    #\n",
    "    #if root[\"root_guess\"] not in [\"śr̥\", \"dr̥\", \"pr̥\"]:\n",
    "    #if root[\"root_guess\"] not in [\"i\", \"uṣ\", \"mi mī\", \"muṣ\"]:\n",
    "    #if root[\"root_guess\"] not in [\"uṣ\", \"muṣ\"]:\n",
    "    #if root[\"root_guess\"] not in [\"vr̥ vr̥̄\", \"vr̥\", \"śrī\", \"śrī 2\", \"aśⁱ\", \"aś\", \"gr̥̄ 1\", \"gr̥\"]:\n",
    "    #if root[\"root_guess\"] not in [\"pū\", \"gr̥bh\", \"iṣ\"]:\n",
    "        #root[\"strong_attestations\"] = ''\n",
    "        #root[\"weak_attestations\"] = ''\n",
    "        #roots.append(root)\n",
    "        #continue                   \n",
    "\n",
    "    # test cases\n",
    "    #results = search_verb_form_attestations_vedaweb(\"iṣ 1\", \"iṣṇā\", 10)\n",
    "    #results = search_verb_form_attestations_vedaweb(\"pū\", \"pun\", 10)   \n",
    "        \n",
    "    results_strong = search_verb_form_attestations_vedaweb(\n",
    "        root[\"root_guess\"], root[\"strong_stem\"], 100\n",
    "    )\n",
    "    results_weak = search_verb_form_attestations_vedaweb(\n",
    "        root[\"root_guess\"], root[\"weak_stem\"], 100\n",
    "    )\n",
    "\n",
    "    #pprint(results_strong[\"09.067.27\"])\n",
    "    #pprint(results_strong)\n",
    "    #pprint(results_weak)\n",
    "    \n",
    "    # unlikely to happen but still test for this\n",
    "    if (results_strong[\"root_vedaweb\"] and results_weak[\"root_vedaweb\"] and\n",
    "            results_strong[\"root_vedaweb\"] != results_weak[\"root_vedaweb\"]\n",
    "        ):\n",
    "        raise Exception(\n",
    "            f\"Root '{results_strong['root_vedaweb']}' inferred from strong-stem results \" +\n",
    "            f\"does not match root '{results_weak['root_vedaweb']}' from weak-stem results\"\n",
    "        )\n",
    "    # both strong and weak results are the same (or one of them is None) by this point\n",
    "    # so can generalize in either order here  \n",
    "    results_root_vedaweb = results_weak[\"root_vedaweb\"] or results_strong[\"root_vedaweb\"]\n",
    "    \n",
    "    if results_root_vedaweb and root[\"root_guess\"] != results_root_vedaweb:\n",
    "        # FIXME add notes colummn?: root form originally present as \"\"\n",
    "        print(\n",
    "            f\"note: using '{results_root_vedaweb}' for root guess {root['root_guess']}\",\n",
    "            \"(as done in vedaweb)\"\n",
    "        )\n",
    "        # FIXME handle this better without losing the order of the column?\n",
    "        root[\"root\"] = results_root_vedaweb\n",
    "        #root[\"root_variant_vedaweb\"] = results_root_vedaweb\n",
    "    else:\n",
    "        #root[\"root_variant_vedaweb\"] = ''\n",
    "        root[\"root\"] = root[\"root_guess\"]\n",
    "    \n",
    "    root[\"strong_attestations\"] = \" \".join(list(results_strong[\"results\"].keys()))\n",
    "    root[\"strong_attestations_total\"] = results_strong['total']\n",
    "    \n",
    "    root[\"weak_attestations\"] = \" \".join(list(results_weak[\"results\"].keys()))\n",
    "    root[\"weak_attestations_total\"] = results_weak['total']\n",
    "    \n",
    "    #root[\"strong_attestations_data\"] = results_strong\n",
    "    #root[\"weak_attestations_data\"] = results_weak\n",
    "    \n",
    "    roots.append(root)\n",
    "    \n",
    "    # save full results data, for use later\n",
    "    roots_attested_words_by_stanza[root[\"root\"]] = {\n",
    "        \"strong\": results_strong[\"results\"],\n",
    "        \"weak\": results_weak[\"results\"]\n",
    "    }\n",
    "    \n",
    "    # useful diagnostic message\n",
    "    print(\n",
    "        # print the variant root form found in vedaweb, if it's there\n",
    "        #f\"{' (' + root['root_variant_vedaweb'] + ')' if root['root_variant_vedaweb'] else ''}\", \n",
    "        f\"{root['root']}: {results_strong['total']} strong, {results_weak['total']} weak attestations\"\n",
    "    )\n",
    "    \n",
    "    # so that we don't hammer the api\n",
    "    #time.sleep(0.5)\n",
    "\n",
    "#pprint(roots)\n",
    "\n",
    "temp = set()\n",
    "dup_roots = [root[\"root\"] for root in roots if root[\"root\"] in temp or temp.add(root[\"root\"])]\n",
    "if len(dup_roots) > 0:\n",
    "    # means some other roots also resolved to these during our search\n",
    "    # we need to ensure our code handles these too now\n",
    "    raise Exception(f\"Final list of roots contain duplicates: {dup_roots}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "634b5430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_guess</th>\n",
       "      <th>variant_no</th>\n",
       "      <th>strong_stem</th>\n",
       "      <th>weak_stem</th>\n",
       "      <th>weak_only</th>\n",
       "      <th>attestation_texts</th>\n",
       "      <th>language_period</th>\n",
       "      <th>root</th>\n",
       "      <th>strong_attestations</th>\n",
       "      <th>strong_attestations_total</th>\n",
       "      <th>weak_attestations</th>\n",
       "      <th>weak_attestations_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>None</td>\n",
       "      <td>inā</td>\n",
       "      <td>inī</td>\n",
       "      <td>True</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>i</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>iṣṇā</td>\n",
       "      <td>iṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>iṣ 1</td>\n",
       "      <td>01.063.02</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ubh</td>\n",
       "      <td>None</td>\n",
       "      <td>ubhnā</td>\n",
       "      <td>ubhnī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>ubh</td>\n",
       "      <td>01.063.04 04.019.04</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>uṣṇā</td>\n",
       "      <td>uṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>uṣ</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kṣi</td>\n",
       "      <td>None</td>\n",
       "      <td>kṣiṇā</td>\n",
       "      <td>kṣiṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>kṣī</td>\n",
       "      <td>04.018.12 10.027.04 10.027.13</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  root_guess variant_no strong_stem weak_stem  weak_only attestation_texts  \\\n",
       "0          i       None         inā       inī       True                V.   \n",
       "1         iṣ       None        iṣṇā      iṣṇī      False              None   \n",
       "2        ubh       None       ubhnā     ubhnī      False                V.   \n",
       "3         uṣ       None        uṣṇā      uṣṇī      False                V.   \n",
       "4        kṣi       None       kṣiṇā     kṣiṇī      False              V.B.   \n",
       "\n",
       "  language_period  root            strong_attestations  \\\n",
       "0         Earlier     i                                  \n",
       "1         Earlier  iṣ 1                      01.063.02   \n",
       "2         Earlier   ubh            01.063.04 04.019.04   \n",
       "3         Earlier    uṣ                                  \n",
       "4         Earlier   kṣī  04.018.12 10.027.04 10.027.13   \n",
       "\n",
       "   strong_attestations_total weak_attestations  weak_attestations_total  \n",
       "0                          0                                          0  \n",
       "1                          1                                          0  \n",
       "2                          2                                          0  \n",
       "3                          0                                          0  \n",
       "4                          3                                          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"data/roots_ninth_class_attestations.json\", 'w') as f:\n",
    "    json.dump(roots_attested_words_by_stanza, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "import pandas\n",
    "df_roots = pandas.DataFrame.from_dict(roots)\n",
    "df_roots.to_csv(\"data/roots_ninth_class.csv\", index=None)\n",
    "df_roots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6305b117",
   "metadata": {},
   "source": [
    "### Validation: Checking for missing roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00bd4bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_guess</th>\n",
       "      <th>variant_no</th>\n",
       "      <th>strong_stem</th>\n",
       "      <th>weak_stem</th>\n",
       "      <th>weak_only</th>\n",
       "      <th>attestation_texts</th>\n",
       "      <th>language_period</th>\n",
       "      <th>root</th>\n",
       "      <th>strong_attestations</th>\n",
       "      <th>strong_attestations_total</th>\n",
       "      <th>weak_attestations</th>\n",
       "      <th>weak_attestations_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>aśⁱ</td>\n",
       "      <td>1</td>\n",
       "      <td>aśnā</td>\n",
       "      <td>aśnī</td>\n",
       "      <td>True</td>\n",
       "      <td>E.</td>\n",
       "      <td>Later</td>\n",
       "      <td>aśⁱ</td>\n",
       "      <td>09.067.31 10.085.03 10.085.04</td>\n",
       "      <td>3</td>\n",
       "      <td>07.073.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>badh</td>\n",
       "      <td>None</td>\n",
       "      <td>badhnā</td>\n",
       "      <td>badhnī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>bandh</td>\n",
       "      <td>10.085.24</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gr̥bh</td>\n",
       "      <td>None</td>\n",
       "      <td>gr̥bhṇā</td>\n",
       "      <td>gr̥bhṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>gr̥bhⁱ</td>\n",
       "      <td>01.055.02 01.163.02 03.030.05 05.031.07 07.101...</td>\n",
       "      <td>10</td>\n",
       "      <td>09.046.04 09.106.03 10.062.01 10.062.02 10.062...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gr̥h</td>\n",
       "      <td>None</td>\n",
       "      <td>gr̥hṇā</td>\n",
       "      <td>gr̥hṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>gr̥hⁱ</td>\n",
       "      <td>04.057.07</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gr̥̄ 1</td>\n",
       "      <td>1</td>\n",
       "      <td>gr̥ṇā</td>\n",
       "      <td>gr̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>gr̥̄ 1</td>\n",
       "      <td>01.048.04 01.054.07 01.147.02 05.027.03 05.041...</td>\n",
       "      <td>10</td>\n",
       "      <td>01.010.04 01.015.03 01.042.10 01.048.14 01.053...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hr̥</td>\n",
       "      <td>None</td>\n",
       "      <td>hr̥ṇā</td>\n",
       "      <td>hr̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>hr̥̄</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>02.033.15 07.086.03 07.104.14 08.002.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>iṣṇā</td>\n",
       "      <td>iṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>iṣ 1</td>\n",
       "      <td>01.063.02</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jī</td>\n",
       "      <td>None</td>\n",
       "      <td>jinā</td>\n",
       "      <td>jinī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>jyā</td>\n",
       "      <td>05.034.05 09.055.04 10.027.04</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>jā</td>\n",
       "      <td>None</td>\n",
       "      <td>jānā</td>\n",
       "      <td>jānī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>jñā</td>\n",
       "      <td>01.163.06 01.164.16 01.164.37 04.004.06 05.061...</td>\n",
       "      <td>8</td>\n",
       "      <td>01.051.08 01.094.08 07.054.01 08.018.15 10.034.04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jū</td>\n",
       "      <td>None</td>\n",
       "      <td>junā</td>\n",
       "      <td>junī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>jū</td>\n",
       "      <td>01.027.07 01.071.06 01.186.05 07.086.07</td>\n",
       "      <td>4</td>\n",
       "      <td>09.079.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>krī</td>\n",
       "      <td>None</td>\n",
       "      <td>krīṇā</td>\n",
       "      <td>krīṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>krī</td>\n",
       "      <td>04.024.10</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kṣi</td>\n",
       "      <td>None</td>\n",
       "      <td>kṣiṇā</td>\n",
       "      <td>kṣiṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>kṣī</td>\n",
       "      <td>04.018.12 10.027.04 10.027.13</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>math</td>\n",
       "      <td>None</td>\n",
       "      <td>mathnā</td>\n",
       "      <td>mathnī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>mathⁱ</td>\n",
       "      <td>01.093.06</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mr̥</td>\n",
       "      <td>None</td>\n",
       "      <td>mr̥ṇā</td>\n",
       "      <td>mr̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>mr̥̄ 1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>04.004.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>muṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>muṣṇā</td>\n",
       "      <td>muṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>muṣⁱ</td>\n",
       "      <td>01.131.04 06.044.22 10.067.06</td>\n",
       "      <td>3</td>\n",
       "      <td>01.093.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mi mī</td>\n",
       "      <td>None</td>\n",
       "      <td>minā mīnā</td>\n",
       "      <td>minī mīnī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>mī 1</td>\n",
       "      <td>01.032.04 01.071.10 01.123.09 01.124.03 01.179...</td>\n",
       "      <td>23</td>\n",
       "      <td>01.025.01 10.134.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>prī</td>\n",
       "      <td>None</td>\n",
       "      <td>prīṇā</td>\n",
       "      <td>prīṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>prī</td>\n",
       "      <td>08.023.16</td>\n",
       "      <td>1</td>\n",
       "      <td>07.007.03 10.101.07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pr̥</td>\n",
       "      <td>None</td>\n",
       "      <td>pr̥ṇā</td>\n",
       "      <td>pr̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>pr̥̄ 1</td>\n",
       "      <td>01.125.05 02.030.07 03.006.02 04.018.05 06.047...</td>\n",
       "      <td>12</td>\n",
       "      <td>01.023.21 05.005.05 07.065.04 10.009.07 10.117...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pū</td>\n",
       "      <td>None</td>\n",
       "      <td>punā</td>\n",
       "      <td>punī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>pū</td>\n",
       "      <td>01.133.01 01.160.03 09.001.06 09.067.22 09.104...</td>\n",
       "      <td>6</td>\n",
       "      <td>09.067.24 09.067.27 01.015.02 07.085.01 08.012...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ram</td>\n",
       "      <td>None</td>\n",
       "      <td>ramṇā</td>\n",
       "      <td>ramṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>ram</td>\n",
       "      <td>02.012.02 02.015.05 05.032.01 10.149.01</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ri</td>\n",
       "      <td>None</td>\n",
       "      <td>riṇā</td>\n",
       "      <td>riṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>rī</td>\n",
       "      <td>01.056.06 01.061.13 01.127.04 01.148.04 01.166...</td>\n",
       "      <td>20</td>\n",
       "      <td>01.117.04 01.117.11 01.117.19 01.124.07 01.161...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>skabh</td>\n",
       "      <td>None</td>\n",
       "      <td>skabhnā</td>\n",
       "      <td>skabhnī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>skambhⁱ</td>\n",
       "      <td>10.006.03</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>stabh</td>\n",
       "      <td>None</td>\n",
       "      <td>stabhnā</td>\n",
       "      <td>stabhnī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>stambhⁱ</td>\n",
       "      <td>02.012.02 02.013.10 02.017.05 03.030.09 03.053...</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>str̥</td>\n",
       "      <td>None</td>\n",
       "      <td>str̥ṇā</td>\n",
       "      <td>str̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>str̥̄</td>\n",
       "      <td>08.041.08 08.063.07</td>\n",
       "      <td>2</td>\n",
       "      <td>01.013.05 03.004.04 05.026.08 06.067.02 07.017...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>si</td>\n",
       "      <td>None</td>\n",
       "      <td>sinā</td>\n",
       "      <td>sinī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>sā si</td>\n",
       "      <td>01.125.02</td>\n",
       "      <td>1</td>\n",
       "      <td>07.084.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ubh</td>\n",
       "      <td>None</td>\n",
       "      <td>ubhnā</td>\n",
       "      <td>ubhnī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>ubh</td>\n",
       "      <td>01.063.04 04.019.04</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>vr̥ vr̥̄</td>\n",
       "      <td>2</td>\n",
       "      <td>vr̥ṇā</td>\n",
       "      <td>vr̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>vr̥ vr̥̄</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>01.139.01 09.066.18 10.013.04 10.036.11 01.012...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>śrath</td>\n",
       "      <td>None</td>\n",
       "      <td>śrathnā</td>\n",
       "      <td>śrathnī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>śrathⁱ</td>\n",
       "      <td>10.171.03</td>\n",
       "      <td>1</td>\n",
       "      <td>09.069.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>śrī</td>\n",
       "      <td>1</td>\n",
       "      <td>śrīṇā</td>\n",
       "      <td>śrīṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>śrī</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>05.006.09 08.002.11 09.011.06 09.046.04 10.061.03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>śr̥</td>\n",
       "      <td>None</td>\n",
       "      <td>śr̥ṇā</td>\n",
       "      <td>śr̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>śr̥̄ 1</td>\n",
       "      <td>10.089.06 10.089.08 10.138.04</td>\n",
       "      <td>3</td>\n",
       "      <td>10.087.14 10.087.10 03.030.17 07.104.01 10.087...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root_guess variant_no strong_stem  weak_stem  weak_only attestation_texts  \\\n",
       "48        aśⁱ          1        aśnā       aśnī       True                E.   \n",
       "39       badh       None      badhnā     badhnī      False              None   \n",
       "6       gr̥bh       None     gr̥bhṇā    gr̥bhṇī      False              V.B.   \n",
       "35       gr̥h       None      gr̥hṇā     gr̥hṇī      False              None   \n",
       "33     gr̥̄ 1          1       gr̥ṇā      gr̥ṇī      False              None   \n",
       "29        hr̥       None       hr̥ṇā      hr̥ṇī      False              V.B.   \n",
       "1          iṣ       None        iṣṇā       iṣṇī      False              None   \n",
       "8          jī       None        jinā       jinī      False              None   \n",
       "36         jā       None        jānā       jānī      False              None   \n",
       "7          jū       None        junā       junī      False                V.   \n",
       "32        krī       None       krīṇā      krīṇī      False              None   \n",
       "4         kṣi       None       kṣiṇā      kṣiṇī      False              V.B.   \n",
       "40       math       None      mathnā     mathnī      False              None   \n",
       "15        mr̥       None       mr̥ṇā      mr̥ṇī      False                V.   \n",
       "41        muṣ       None       muṣṇā      muṣṇī      False              None   \n",
       "14      mi mī       None   minā mīnā  minī mīnī      False              V.B.   \n",
       "38        prī       None       prīṇā      prīṇī      False              None   \n",
       "11        pr̥       None       pr̥ṇā      pr̥ṇī      False              None   \n",
       "37         pū       None        punā       punī      False              None   \n",
       "16        ram       None       ramṇā      ramṇī      False              V.B.   \n",
       "17         ri       None        riṇā       riṇī      False              None   \n",
       "27      skabh       None     skabhnā    skabhnī      False              V.B.   \n",
       "46      stabh       None     stabhnā    stabhnī      False              None   \n",
       "47       str̥       None      str̥ṇā     str̥ṇī      False              None   \n",
       "25         si       None        sinā       sinī      False              V.B.   \n",
       "2         ubh       None       ubhnā      ubhnī      False                V.   \n",
       "44   vr̥ vr̥̄          2       vr̥ṇā      vr̥ṇī      False              None   \n",
       "22      śrath       None     śrathnā    śrathnī      False                V.   \n",
       "23        śrī          1       śrīṇā      śrīṇī      False              V.B.   \n",
       "45        śr̥       None       śr̥ṇā      śr̥ṇī      False              None   \n",
       "\n",
       "    language_period      root  \\\n",
       "48            Later       aśⁱ   \n",
       "39  Earlier & Later     bandh   \n",
       "6           Earlier    gr̥bhⁱ   \n",
       "35  Earlier & Later     gr̥hⁱ   \n",
       "33  Earlier & Later    gr̥̄ 1   \n",
       "29          Earlier      hr̥̄   \n",
       "1           Earlier      iṣ 1   \n",
       "8           Earlier       jyā   \n",
       "36  Earlier & Later       jñā   \n",
       "7           Earlier        jū   \n",
       "32  Earlier & Later       krī   \n",
       "4           Earlier       kṣī   \n",
       "40  Earlier & Later     mathⁱ   \n",
       "15          Earlier    mr̥̄ 1   \n",
       "41  Earlier & Later      muṣⁱ   \n",
       "14          Earlier      mī 1   \n",
       "38  Earlier & Later       prī   \n",
       "11          Earlier    pr̥̄ 1   \n",
       "37  Earlier & Later        pū   \n",
       "16          Earlier       ram   \n",
       "17          Earlier        rī   \n",
       "27          Earlier   skambhⁱ   \n",
       "46  Earlier & Later   stambhⁱ   \n",
       "47  Earlier & Later     str̥̄   \n",
       "25          Earlier     sā si   \n",
       "2           Earlier       ubh   \n",
       "44  Earlier & Later  vr̥ vr̥̄   \n",
       "22          Earlier    śrathⁱ   \n",
       "23          Earlier       śrī   \n",
       "45  Earlier & Later    śr̥̄ 1   \n",
       "\n",
       "                                  strong_attestations  \\\n",
       "48                      09.067.31 10.085.03 10.085.04   \n",
       "39                                          10.085.24   \n",
       "6   01.055.02 01.163.02 03.030.05 05.031.07 07.101...   \n",
       "35                                          04.057.07   \n",
       "33  01.048.04 01.054.07 01.147.02 05.027.03 05.041...   \n",
       "29                                                      \n",
       "1                                           01.063.02   \n",
       "8                       05.034.05 09.055.04 10.027.04   \n",
       "36  01.163.06 01.164.16 01.164.37 04.004.06 05.061...   \n",
       "7             01.027.07 01.071.06 01.186.05 07.086.07   \n",
       "32                                          04.024.10   \n",
       "4                       04.018.12 10.027.04 10.027.13   \n",
       "40                                          01.093.06   \n",
       "15                                                      \n",
       "41                      01.131.04 06.044.22 10.067.06   \n",
       "14  01.032.04 01.071.10 01.123.09 01.124.03 01.179...   \n",
       "38                                          08.023.16   \n",
       "11  01.125.05 02.030.07 03.006.02 04.018.05 06.047...   \n",
       "37  01.133.01 01.160.03 09.001.06 09.067.22 09.104...   \n",
       "16            02.012.02 02.015.05 05.032.01 10.149.01   \n",
       "17  01.056.06 01.061.13 01.127.04 01.148.04 01.166...   \n",
       "27                                          10.006.03   \n",
       "46  02.012.02 02.013.10 02.017.05 03.030.09 03.053...   \n",
       "47                                08.041.08 08.063.07   \n",
       "25                                          01.125.02   \n",
       "2                                 01.063.04 04.019.04   \n",
       "44                                                      \n",
       "22                                          10.171.03   \n",
       "23                                                      \n",
       "45                      10.089.06 10.089.08 10.138.04   \n",
       "\n",
       "    strong_attestations_total  \\\n",
       "48                          3   \n",
       "39                          1   \n",
       "6                          10   \n",
       "35                          1   \n",
       "33                         10   \n",
       "29                          0   \n",
       "1                           1   \n",
       "8                           3   \n",
       "36                          8   \n",
       "7                           4   \n",
       "32                          1   \n",
       "4                           3   \n",
       "40                          1   \n",
       "15                          0   \n",
       "41                          3   \n",
       "14                         23   \n",
       "38                          1   \n",
       "11                         12   \n",
       "37                          6   \n",
       "16                          4   \n",
       "17                         20   \n",
       "27                          1   \n",
       "46                         15   \n",
       "47                          2   \n",
       "25                          1   \n",
       "2                           2   \n",
       "44                          0   \n",
       "22                          1   \n",
       "23                          0   \n",
       "45                          3   \n",
       "\n",
       "                                    weak_attestations  weak_attestations_total  \n",
       "48                                          07.073.02                        1  \n",
       "39                                                                           0  \n",
       "6   09.046.04 09.106.03 10.062.01 10.062.02 10.062...                        6  \n",
       "35                                                                           0  \n",
       "33  01.010.04 01.015.03 01.042.10 01.048.14 01.053...                       40  \n",
       "29            02.033.15 07.086.03 07.104.14 08.002.19                        4  \n",
       "1                                                                            0  \n",
       "8                                                                            0  \n",
       "36  01.051.08 01.094.08 07.054.01 08.018.15 10.034.04                        5  \n",
       "7                                           09.079.02                        1  \n",
       "32                                                                           0  \n",
       "4                                                                            0  \n",
       "40                                                                           0  \n",
       "15                                          04.004.05                        1  \n",
       "41                                          01.093.04                        1  \n",
       "14                                01.025.01 10.134.07                        2  \n",
       "38                                07.007.03 10.101.07                        2  \n",
       "11  01.023.21 05.005.05 07.065.04 10.009.07 10.117...                        6  \n",
       "37  09.067.24 09.067.27 01.015.02 07.085.01 08.012...                       15  \n",
       "16                                                                           0  \n",
       "17  01.117.04 01.117.11 01.117.19 01.124.07 01.161...                        9  \n",
       "27                                                                           0  \n",
       "46                                                                           0  \n",
       "47  01.013.05 03.004.04 05.026.08 06.067.02 07.017...                        7  \n",
       "25                                          07.084.02                        1  \n",
       "2                                                                            0  \n",
       "44  01.139.01 09.066.18 10.013.04 10.036.11 01.012...                       85  \n",
       "22                                          09.069.03                        1  \n",
       "23  05.006.09 08.002.11 09.011.06 09.046.04 10.061.03                        5  \n",
       "45  10.087.14 10.087.10 03.030.17 07.104.01 10.087...                        6  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roots attested in RV\n",
    "df_roots.query(\n",
    "    'strong_attestations_total > 0 or weak_attestations_total > 0'\n",
    ").sort_values(\"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf0de0a",
   "metadata": {},
   "source": [
    "TODO explain cases where root_guess and root differ\n",
    "\n",
    "eg: iS 'send' being marked with 1 automatically from vedaweb (same as what lubotsky gives)\n",
    "whitney actually has this as 2 in main root list but since stem does not have variants with it, it's not marked later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbefd7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_guess</th>\n",
       "      <th>variant_no</th>\n",
       "      <th>strong_stem</th>\n",
       "      <th>weak_stem</th>\n",
       "      <th>weak_only</th>\n",
       "      <th>attestation_texts</th>\n",
       "      <th>language_period</th>\n",
       "      <th>root</th>\n",
       "      <th>strong_attestations</th>\n",
       "      <th>strong_attestations_total</th>\n",
       "      <th>weak_attestations</th>\n",
       "      <th>weak_attestations_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>aś</td>\n",
       "      <td>2</td>\n",
       "      <td>aśnā</td>\n",
       "      <td>aśnī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>aś</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bhrī</td>\n",
       "      <td>None</td>\n",
       "      <td>bhrīṇā</td>\n",
       "      <td>bhrīṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>bhrī</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>dhu dhū</td>\n",
       "      <td>None</td>\n",
       "      <td>dhunā dhūnā</td>\n",
       "      <td>dhunī dhūnī</td>\n",
       "      <td>True</td>\n",
       "      <td>C.</td>\n",
       "      <td>Later</td>\n",
       "      <td>dhu dhū</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>drū</td>\n",
       "      <td>None</td>\n",
       "      <td>drūṇā</td>\n",
       "      <td>drūṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>drū</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dr̥</td>\n",
       "      <td>None</td>\n",
       "      <td>dr̥ṇā</td>\n",
       "      <td>dr̥ṇī</td>\n",
       "      <td>True</td>\n",
       "      <td>B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>dr̥</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>grath</td>\n",
       "      <td>None</td>\n",
       "      <td>grathnā</td>\n",
       "      <td>grathnī</td>\n",
       "      <td>False</td>\n",
       "      <td>B. +</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>grath</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gr̥</td>\n",
       "      <td>2</td>\n",
       "      <td>gr̥ṇā</td>\n",
       "      <td>gr̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.S.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>gr̥</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hru</td>\n",
       "      <td>None</td>\n",
       "      <td>hrunā</td>\n",
       "      <td>hrunī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>hru</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i</td>\n",
       "      <td>None</td>\n",
       "      <td>inā</td>\n",
       "      <td>inī</td>\n",
       "      <td>True</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>i</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>kliś</td>\n",
       "      <td>None</td>\n",
       "      <td>kliśnā</td>\n",
       "      <td>kliśnī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Later</td>\n",
       "      <td>kliś</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>kuṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>kuṣṇā</td>\n",
       "      <td>kuṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>C.</td>\n",
       "      <td>Later</td>\n",
       "      <td>kuṣ</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>lu</td>\n",
       "      <td>None</td>\n",
       "      <td>lunā</td>\n",
       "      <td>lunī</td>\n",
       "      <td>False</td>\n",
       "      <td>B. +</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>lu</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mr̥d</td>\n",
       "      <td>None</td>\n",
       "      <td>mr̥dnā</td>\n",
       "      <td>mr̥dnī</td>\n",
       "      <td>False</td>\n",
       "      <td>S. +</td>\n",
       "      <td>Earlier &amp; Later</td>\n",
       "      <td>mr̥d</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pruṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>pruṣṇā</td>\n",
       "      <td>pruṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>pruṣ</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>puṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>puṣṇā</td>\n",
       "      <td>puṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>Later</td>\n",
       "      <td>puṣ</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>spr̥</td>\n",
       "      <td>None</td>\n",
       "      <td>spr̥ṇā</td>\n",
       "      <td>spr̥ṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>spr̥</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>subh</td>\n",
       "      <td>None</td>\n",
       "      <td>subhnā</td>\n",
       "      <td>subhnī</td>\n",
       "      <td>False</td>\n",
       "      <td>B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>subh</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uṣ</td>\n",
       "      <td>None</td>\n",
       "      <td>uṣṇā</td>\n",
       "      <td>uṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>uṣ</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vli vlī</td>\n",
       "      <td>None</td>\n",
       "      <td>vlinā vlīnā</td>\n",
       "      <td>vlinī vlīnī</td>\n",
       "      <td>False</td>\n",
       "      <td>B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>vli vlī</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vr̥</td>\n",
       "      <td>1</td>\n",
       "      <td>vr̥ṇā</td>\n",
       "      <td>vr̥ṇī</td>\n",
       "      <td>True</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>vr̥</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>śam</td>\n",
       "      <td>None</td>\n",
       "      <td>śamnā</td>\n",
       "      <td>śamnī</td>\n",
       "      <td>True</td>\n",
       "      <td>B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>śam</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ścam</td>\n",
       "      <td>None</td>\n",
       "      <td>ścamnā</td>\n",
       "      <td>ścamnī</td>\n",
       "      <td>True</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>ścam</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>śrī 2</td>\n",
       "      <td>2</td>\n",
       "      <td>śrīṇā</td>\n",
       "      <td>śrīṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>śrī 2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root_guess variant_no  strong_stem    weak_stem  weak_only  \\\n",
       "31         aś          2         aśnā         aśnī      False   \n",
       "13       bhrī       None       bhrīṇā       bhrīṇī      False   \n",
       "51    dhu dhū       None  dhunā dhūnā  dhunī dhūnī       True   \n",
       "10        drū       None        drūṇā        drūṇī      False   \n",
       "9         dr̥       None        dr̥ṇā        dr̥ṇī       True   \n",
       "34      grath       None      grathnā      grathnī      False   \n",
       "5         gr̥          2        gr̥ṇā        gr̥ṇī      False   \n",
       "30        hru       None        hrunā        hrunī      False   \n",
       "0           i       None          inā          inī       True   \n",
       "50       kliś       None       kliśnā       kliśnī      False   \n",
       "49        kuṣ       None        kuṣṇā        kuṣṇī      False   \n",
       "43         lu       None         lunā         lunī      False   \n",
       "42       mr̥d       None       mr̥dnā       mr̥dnī      False   \n",
       "12       pruṣ       None       pruṣṇā       pruṣṇī      False   \n",
       "52        puṣ       None        puṣṇā        puṣṇī      False   \n",
       "28       spr̥       None       spr̥ṇā       spr̥ṇī      False   \n",
       "26       subh       None       subhnā       subhnī      False   \n",
       "3          uṣ       None         uṣṇā         uṣṇī      False   \n",
       "19    vli vlī       None  vlinā vlīnā  vlinī vlīnī      False   \n",
       "18        vr̥          1        vr̥ṇā        vr̥ṇī       True   \n",
       "20        śam       None        śamnā        śamnī       True   \n",
       "21       ścam       None       ścamnā       ścamnī       True   \n",
       "24      śrī 2          2        śrīṇā        śrīṇī      False   \n",
       "\n",
       "   attestation_texts  language_period     root strong_attestations  \\\n",
       "31              None  Earlier & Later       aś                       \n",
       "13                V.          Earlier     bhrī                       \n",
       "51                C.            Later  dhu dhū                       \n",
       "10              V.B.          Earlier      drū                       \n",
       "9                 B.          Earlier      dr̥                       \n",
       "34              B. +  Earlier & Later    grath                       \n",
       "5               V.S.          Earlier      gr̥                       \n",
       "30                V.          Earlier      hru                       \n",
       "0                 V.          Earlier        i                       \n",
       "50              None            Later     kliś                       \n",
       "49                C.            Later      kuṣ                       \n",
       "43              B. +  Earlier & Later       lu                       \n",
       "42              S. +  Earlier & Later     mr̥d                       \n",
       "12                B.          Earlier     pruṣ                       \n",
       "52              None            Later      puṣ                       \n",
       "28                B.          Earlier     spr̥                       \n",
       "26                B.          Earlier     subh                       \n",
       "3                 V.          Earlier       uṣ                       \n",
       "19                B.          Earlier  vli vlī                       \n",
       "18                V.          Earlier      vr̥                       \n",
       "20                B.          Earlier      śam                       \n",
       "21                V.          Earlier     ścam                       \n",
       "24              V.B.          Earlier    śrī 2                       \n",
       "\n",
       "    strong_attestations_total weak_attestations  weak_attestations_total  \n",
       "31                          0                                          0  \n",
       "13                          0                                          0  \n",
       "51                          0                                          0  \n",
       "10                          0                                          0  \n",
       "9                           0                                          0  \n",
       "34                          0                                          0  \n",
       "5                           0                                          0  \n",
       "30                          0                                          0  \n",
       "0                           0                                          0  \n",
       "50                          0                                          0  \n",
       "49                          0                                          0  \n",
       "43                          0                                          0  \n",
       "42                          0                                          0  \n",
       "12                          0                                          0  \n",
       "52                          0                                          0  \n",
       "28                          0                                          0  \n",
       "26                          0                                          0  \n",
       "3                           0                                          0  \n",
       "19                          0                                          0  \n",
       "18                          0                                          0  \n",
       "20                          0                                          0  \n",
       "21                          0                                          0  \n",
       "24                          0                                          0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to print without index on the left\n",
    "#from IPython.display import HTML\n",
    "#HTML(df_roots.to_html(index=False))\n",
    "\n",
    "# roots not attested in RV\n",
    "df_roots.query(\n",
    "    'strong_attestations_total == 0 and weak_attestations_total == 0'\n",
    ").sort_values(\"root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e79fbf",
   "metadata": {},
   "source": [
    "TODO Test these with different length of final root vowel? just to see if we catch anything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c19962",
   "metadata": {},
   "source": [
    "## Organizing Data by Verse Lines (pādas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfaf1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "#df_roots = pandas.read_csv(\"data/roots_ninth_class.csv\")\n",
    "df_roots = pandas.read_csv(\"data/roots_ninth_class.csv\", keep_default_na=False)\n",
    "#df_roots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9365ddbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_guess</th>\n",
       "      <th>variant_no</th>\n",
       "      <th>strong_stem</th>\n",
       "      <th>weak_stem</th>\n",
       "      <th>weak_only</th>\n",
       "      <th>attestation_texts</th>\n",
       "      <th>language_period</th>\n",
       "      <th>root</th>\n",
       "      <th>strong_attestations</th>\n",
       "      <th>strong_attestations_total</th>\n",
       "      <th>weak_attestations</th>\n",
       "      <th>weak_attestations_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iṣ</td>\n",
       "      <td></td>\n",
       "      <td>iṣṇā</td>\n",
       "      <td>iṣṇī</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Earlier</td>\n",
       "      <td>iṣ 1</td>\n",
       "      <td>01.063.02</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ubh</td>\n",
       "      <td></td>\n",
       "      <td>ubhnā</td>\n",
       "      <td>ubhnī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>ubh</td>\n",
       "      <td>01.063.04 04.019.04</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kṣi</td>\n",
       "      <td></td>\n",
       "      <td>kṣiṇā</td>\n",
       "      <td>kṣiṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>kṣī</td>\n",
       "      <td>04.018.12 10.027.04 10.027.13</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gr̥bh</td>\n",
       "      <td></td>\n",
       "      <td>gr̥bhṇā</td>\n",
       "      <td>gr̥bhṇī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>gr̥bhⁱ</td>\n",
       "      <td>01.055.02 01.163.02 03.030.05 05.031.07 07.101...</td>\n",
       "      <td>10</td>\n",
       "      <td>09.046.04 09.106.03 10.062.01 10.062.02 10.062...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jū</td>\n",
       "      <td></td>\n",
       "      <td>junā</td>\n",
       "      <td>junī</td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>jū</td>\n",
       "      <td>01.027.07 01.071.06 01.186.05 07.086.07</td>\n",
       "      <td>4</td>\n",
       "      <td>09.079.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  root_guess variant_no strong_stem weak_stem  weak_only attestation_texts  \\\n",
       "1         iṣ                   iṣṇā      iṣṇī      False                     \n",
       "2        ubh                  ubhnā     ubhnī      False                V.   \n",
       "4        kṣi                  kṣiṇā     kṣiṇī      False              V.B.   \n",
       "6      gr̥bh                gr̥bhṇā   gr̥bhṇī      False              V.B.   \n",
       "7         jū                   junā      junī      False                V.   \n",
       "\n",
       "  language_period    root                                strong_attestations  \\\n",
       "1         Earlier    iṣ 1                                          01.063.02   \n",
       "2         Earlier     ubh                                01.063.04 04.019.04   \n",
       "4         Earlier     kṣī                      04.018.12 10.027.04 10.027.13   \n",
       "6         Earlier  gr̥bhⁱ  01.055.02 01.163.02 03.030.05 05.031.07 07.101...   \n",
       "7         Earlier      jū            01.027.07 01.071.06 01.186.05 07.086.07   \n",
       "\n",
       "   strong_attestations_total  \\\n",
       "1                          1   \n",
       "2                          2   \n",
       "4                          3   \n",
       "6                         10   \n",
       "7                          4   \n",
       "\n",
       "                                   weak_attestations  weak_attestations_total  \n",
       "1                                                                           0  \n",
       "2                                                                           0  \n",
       "4                                                                           0  \n",
       "6  09.046.04 09.106.03 10.062.01 10.062.02 10.062...                        6  \n",
       "7                                          09.079.02                        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO remove test df once we have all the annotations\n",
    "#df_roots_test = df_roots[~df_roots[\"rig_veda_strong_attestations\"].isna()]\n",
    "#df_roots_test = df_roots[df_roots[\"rig_veda_strong_attestations\"].str.len() > 0]\n",
    "df_roots_test = df_roots.query('strong_attestations != \"\" or weak_attestations != \"\"')\n",
    "df_roots_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05fb2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5579f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attestation_texts': '',\n",
      " 'language_period': 'Earlier',\n",
      " 'line_no': '01.063.02',\n",
      " 'root': 'iṣ 1',\n",
      " 'root_guess': 'iṣ',\n",
      " 'stem': 'iṣṇā',\n",
      " 'stem_type': 'strong',\n",
      " 'variant_no': '',\n",
      " 'weak_only': False}\n"
     ]
    }
   ],
   "source": [
    "rv_lines = []\n",
    "\n",
    "roots_data = df_roots_test.to_dict(\"records\")\n",
    "\n",
    "for root in roots_data:\n",
    "    rv_weak_line_nos = root.pop(\"weak_attestations\").split()\n",
    "    rv_strong_line_nos = root.pop(\"strong_attestations\").split()\n",
    "    # FIXME just eliminate these? since these are only stanza\n",
    "    root.pop(\"weak_attestations_total\")\n",
    "    root.pop(\"strong_attestations_total\")\n",
    "    \n",
    "    #rv_weak_attestations_data = root.pop(\"rig_veda_weak_attestations_data\")\n",
    "    #rv_strong_attestations_data = root.pop(\"rig_veda_strong_attestations_data\")\n",
    "    \n",
    "    weak_stem = root.pop(\"weak_stem\")\n",
    "    strong_stem = root.pop(\"strong_stem\")\n",
    "    \n",
    "    for line_no in rv_weak_line_nos:\n",
    "        rv_lines.append({\"line_no\": line_no, \"stem\": weak_stem, \"stem_type\": \"weak\"} | root)\n",
    "        \n",
    "    for line_no in rv_strong_line_nos: \n",
    "        rv_lines.append({\"line_no\": line_no, \"stem\": strong_stem, \"stem_type\": \"strong\"} | root)\n",
    "\n",
    "pprint(rv_lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c9552",
   "metadata": {},
   "source": [
    "### Parsing line numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "301290d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attestation_texts': '',\n",
      " 'book': '01',\n",
      " 'hymn': '01.063',\n",
      " 'language_period': 'Earlier',\n",
      " 'line_no': '01.063.02',\n",
      " 'pada': '',\n",
      " 'root': 'iṣ 1',\n",
      " 'root_guess': 'iṣ',\n",
      " 'stanza': '01.063.02',\n",
      " 'stem': 'iṣṇā',\n",
      " 'stem_type': 'strong',\n",
      " 'variant_no': '',\n",
      " 'weak_only': False}\n"
     ]
    }
   ],
   "source": [
    "# \"1.1.1b\" > \"01\" \"001\" \"02\" \"b\"\n",
    "# 01.063.02 > \"01\" \"063\" \"02\" \"\"\n",
    "def parse_rv_line_no(string):\n",
    "    line_no_parts = string.split(\".\")\n",
    "    \n",
    "    book = line_no_parts[0].zfill(2)\n",
    "    hymn = line_no_parts[1].zfill(3)\n",
    "    \n",
    "    last_char = line_no_parts[2][-1]\n",
    "    if last_char.isalpha():\n",
    "        stanza = line_no_parts[2][:-1] # drop the last char\n",
    "        pada = last_char\n",
    "    else:\n",
    "        stanza = line_no_parts[2]\n",
    "        pada = \"\"\n",
    "\n",
    "    stanza = stanza.zfill(2)\n",
    "\n",
    "    return {\n",
    "        \"book\"    : book,\n",
    "        \"hymn\"    : f\"{book}.{hymn}\",\n",
    "        \"stanza\"  : f\"{book}.{hymn}.{stanza}\",\n",
    "        \"pada\"    : f\"{book}.{hymn}.{stanza}.{pada}\" if pada else \"\"\n",
    "        #\"pada_id\" : pada or ''\n",
    "    }    \n",
    "\n",
    "rv_lines = [line | (parse_rv_line_no(line[\"line_no\"])) for line in rv_lines]\n",
    "\n",
    "pprint(rv_lines[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff0341",
   "metadata": {},
   "source": [
    "## Annotating Verse Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ffee3b",
   "metadata": {},
   "source": [
    "### Downloading annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ec30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p downloads/vedaweb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8913e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "VEDAWEB_API_URL = \"https://vedaweb.uni-koeln.de/rigveda/api\"\n",
    "\n",
    "rv_stanza_nos = sorted(list(set([line[\"stanza\"] for line in rv_lines])))\n",
    "print(len(rv_stanza_nos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9974bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for stanza: 01.010.04\n",
      "Getting data for stanza: 01.012.01\n",
      "Getting data for stanza: 01.013.05\n",
      "Getting data for stanza: 01.015.02\n",
      "Getting data for stanza: 01.015.03\n",
      "Getting data for stanza: 01.023.21\n",
      "Getting data for stanza: 01.025.01\n",
      "Getting data for stanza: 01.027.07\n",
      "Getting data for stanza: 01.032.03\n",
      "Getting data for stanza: 01.032.04\n",
      "Getting data for stanza: 01.036.03\n",
      "Getting data for stanza: 01.039.07\n",
      "Getting data for stanza: 01.042.05\n",
      "Getting data for stanza: 01.042.10\n",
      "Getting data for stanza: 01.044.03\n",
      "Getting data for stanza: 01.048.04\n",
      "Getting data for stanza: 01.048.14\n",
      "Getting data for stanza: 01.051.08\n",
      "Getting data for stanza: 01.053.02\n",
      "Getting data for stanza: 01.054.07\n",
      "Getting data for stanza: 01.055.02\n",
      "Getting data for stanza: 01.056.06\n",
      "Getting data for stanza: 01.061.13\n",
      "Getting data for stanza: 01.063.02\n",
      "Getting data for stanza: 01.063.04\n",
      "Getting data for stanza: 01.064.12\n",
      "Getting data for stanza: 01.067.01\n",
      "Getting data for stanza: 01.071.06\n",
      "Getting data for stanza: 01.071.10\n",
      "Getting data for stanza: 01.079.12\n",
      "Getting data for stanza: 01.093.04\n",
      "Getting data for stanza: 01.093.06\n",
      "Getting data for stanza: 01.094.08\n",
      "Getting data for stanza: 01.114.04\n",
      "Getting data for stanza: 01.114.09\n",
      "Getting data for stanza: 01.117.04\n",
      "Getting data for stanza: 01.117.11\n",
      "Getting data for stanza: 01.117.13\n",
      "Getting data for stanza: 01.117.19\n",
      "Getting data for stanza: 01.119.05\n",
      "Getting data for stanza: 01.123.09\n",
      "Getting data for stanza: 01.124.03\n",
      "Getting data for stanza: 01.124.07\n",
      "Getting data for stanza: 01.125.02\n",
      "Getting data for stanza: 01.125.05\n",
      "Getting data for stanza: 01.127.04\n",
      "Getting data for stanza: 01.131.04\n",
      "Getting data for stanza: 01.133.01\n",
      "Getting data for stanza: 01.139.01\n",
      "Getting data for stanza: 01.146.01\n",
      "Getting data for stanza: 01.147.02\n",
      "Getting data for stanza: 01.148.04\n",
      "Getting data for stanza: 01.155.04\n",
      "Getting data for stanza: 01.160.03\n",
      "Getting data for stanza: 01.161.07\n",
      "Getting data for stanza: 01.163.02\n",
      "Getting data for stanza: 01.163.06\n",
      "Getting data for stanza: 01.164.16\n",
      "Getting data for stanza: 01.164.37\n",
      "Getting data for stanza: 01.166.06\n",
      "Getting data for stanza: 01.179.01\n",
      "Getting data for stanza: 01.179.04\n",
      "Getting data for stanza: 01.180.04\n",
      "Getting data for stanza: 01.186.03\n",
      "Getting data for stanza: 01.186.05\n",
      "Getting data for stanza: 02.009.04\n",
      "Getting data for stanza: 02.012.02\n",
      "Getting data for stanza: 02.012.03\n",
      "Getting data for stanza: 02.012.05\n",
      "Getting data for stanza: 02.013.10\n",
      "Getting data for stanza: 02.015.05\n",
      "Getting data for stanza: 02.015.06\n",
      "Getting data for stanza: 02.017.05\n",
      "Getting data for stanza: 02.020.04\n",
      "Getting data for stanza: 02.022.04\n",
      "Getting data for stanza: 02.026.02\n",
      "Getting data for stanza: 02.030.07\n",
      "Getting data for stanza: 02.033.08\n",
      "Getting data for stanza: 02.033.12\n",
      "Getting data for stanza: 02.033.13\n",
      "Getting data for stanza: 02.033.15\n",
      "Getting data for stanza: 02.034.14\n",
      "Getting data for stanza: 02.041.19\n",
      "Getting data for stanza: 03.002.04\n",
      "Getting data for stanza: 03.003.11\n",
      "Getting data for stanza: 03.004.04\n",
      "Getting data for stanza: 03.006.02\n",
      "Getting data for stanza: 03.006.10\n",
      "Getting data for stanza: 03.029.16\n",
      "Getting data for stanza: 03.030.05\n",
      "Getting data for stanza: 03.030.09\n",
      "Getting data for stanza: 03.030.12\n",
      "Getting data for stanza: 03.030.17\n",
      "Getting data for stanza: 03.034.03\n",
      "Getting data for stanza: 03.036.08\n",
      "Getting data for stanza: 03.039.07\n",
      "Getting data for stanza: 03.049.02\n",
      "Getting data for stanza: 03.053.03\n",
      "Getting data for stanza: 03.053.09\n",
      "Getting data for stanza: 03.060.02\n",
      "Getting data for stanza: 04.004.05\n",
      "Getting data for stanza: 04.004.06\n",
      "Getting data for stanza: 04.018.05\n",
      "Getting data for stanza: 04.018.12\n",
      "Getting data for stanza: 04.019.03\n",
      "Getting data for stanza: 04.019.04\n",
      "Getting data for stanza: 04.019.05\n",
      "Getting data for stanza: 04.024.10\n",
      "Getting data for stanza: 04.025.03\n",
      "Getting data for stanza: 04.025.07\n",
      "Getting data for stanza: 04.028.01\n",
      "Getting data for stanza: 04.030.06\n",
      "Getting data for stanza: 04.031.11\n",
      "Getting data for stanza: 04.036.04\n",
      "Getting data for stanza: 04.041.07\n",
      "Getting data for stanza: 04.042.07\n",
      "Getting data for stanza: 04.043.02\n",
      "Getting data for stanza: 04.053.01\n",
      "Getting data for stanza: 04.057.07\n",
      "Getting data for stanza: 05.005.05\n",
      "Getting data for stanza: 05.006.09\n",
      "Getting data for stanza: 05.007.04\n",
      "Getting data for stanza: 05.020.03\n",
      "Getting data for stanza: 05.026.04\n",
      "Getting data for stanza: 05.026.08\n",
      "Getting data for stanza: 05.027.03\n",
      "Getting data for stanza: 05.028.06\n",
      "Getting data for stanza: 05.031.07\n",
      "Getting data for stanza: 05.031.11\n",
      "Getting data for stanza: 05.032.01\n",
      "Getting data for stanza: 05.034.05\n",
      "Getting data for stanza: 05.034.09\n",
      "Getting data for stanza: 05.041.10\n",
      "Getting data for stanza: 05.041.19\n",
      "Getting data for stanza: 05.050.01\n",
      "Getting data for stanza: 05.053.16\n",
      "Getting data for stanza: 05.061.07\n",
      "Getting data for stanza: 05.080.04\n",
      "Getting data for stanza: 05.080.06\n",
      "Getting data for stanza: 05.082.01\n",
      "Getting data for stanza: 05.082.07\n",
      "Getting data for stanza: 06.008.03\n",
      "Getting data for stanza: 06.009.02\n",
      "Getting data for stanza: 06.009.03\n",
      "Getting data for stanza: 06.015.09\n",
      "Getting data for stanza: 06.030.02\n",
      "Getting data for stanza: 06.035.05\n",
      "Getting data for stanza: 06.044.04\n",
      "Getting data for stanza: 06.044.22\n",
      "Getting data for stanza: 06.047.05\n",
      "Getting data for stanza: 06.047.15\n",
      "Getting data for stanza: 06.067.02\n",
      "Getting data for stanza: 06.068.03\n",
      "Getting data for stanza: 07.006.04\n",
      "Getting data for stanza: 07.007.03\n",
      "Getting data for stanza: 07.013.02\n",
      "Getting data for stanza: 07.017.01\n",
      "Getting data for stanza: 07.019.09\n",
      "Getting data for stanza: 07.026.05\n",
      "Getting data for stanza: 07.033.02\n",
      "Getting data for stanza: 07.034.16\n",
      "Getting data for stanza: 07.036.04\n",
      "Getting data for stanza: 07.038.04\n",
      "Getting data for stanza: 07.043.02\n",
      "Getting data for stanza: 07.054.01\n",
      "Getting data for stanza: 07.063.03\n",
      "Getting data for stanza: 07.065.04\n",
      "Getting data for stanza: 07.066.07\n",
      "Getting data for stanza: 07.069.04\n",
      "Getting data for stanza: 07.073.02\n",
      "Getting data for stanza: 07.084.02\n",
      "Getting data for stanza: 07.084.04\n",
      "Getting data for stanza: 07.085.01\n",
      "Getting data for stanza: 07.086.03\n",
      "Getting data for stanza: 07.086.07\n",
      "Getting data for stanza: 07.097.02\n",
      "Getting data for stanza: 07.097.03\n",
      "Getting data for stanza: 07.099.02\n",
      "Getting data for stanza: 07.099.03\n",
      "Getting data for stanza: 07.100.05\n",
      "Getting data for stanza: 07.101.03\n",
      "Getting data for stanza: 07.103.04\n",
      "Getting data for stanza: 07.104.01\n",
      "Getting data for stanza: 07.104.14\n",
      "Getting data for stanza: 08.002.11\n",
      "Getting data for stanza: 08.002.19\n",
      "Getting data for stanza: 08.003.13\n",
      "Getting data for stanza: 08.004.15\n",
      "Getting data for stanza: 08.006.44\n",
      "Getting data for stanza: 08.012.11\n",
      "Getting data for stanza: 08.013.01\n",
      "Getting data for stanza: 08.014.06\n",
      "Getting data for stanza: 08.015.04\n",
      "Getting data for stanza: 08.015.09\n",
      "Getting data for stanza: 08.018.15\n",
      "Getting data for stanza: 08.018.16\n",
      "Getting data for stanza: 08.023.16\n",
      "Getting data for stanza: 08.025.13\n",
      "Getting data for stanza: 08.026.21\n",
      "Getting data for stanza: 08.027.22\n",
      "Getting data for stanza: 08.031.10\n",
      "Getting data for stanza: 08.041.08\n",
      "Getting data for stanza: 08.042.01\n",
      "Getting data for stanza: 08.044.20\n",
      "Getting data for stanza: 08.048.09\n",
      "Getting data for stanza: 08.060.01\n",
      "Getting data for stanza: 08.063.07\n",
      "Getting data for stanza: 08.064.04\n",
      "Getting data for stanza: 08.065.05\n",
      "Getting data for stanza: 08.067.04\n",
      "Getting data for stanza: 08.071.15\n",
      "Getting data for stanza: 08.073.03\n",
      "Getting data for stanza: 08.083.01\n",
      "Getting data for stanza: 08.083.04\n",
      "Getting data for stanza: 08.088.03\n",
      "Getting data for stanza: 08.089.05\n",
      "Getting data for stanza: 08.090.02\n",
      "Getting data for stanza: 08.102.12\n",
      "Getting data for stanza: 09.001.06\n",
      "Getting data for stanza: 09.004.04\n",
      "Getting data for stanza: 09.011.05\n",
      "Getting data for stanza: 09.011.06\n",
      "Getting data for stanza: 09.016.03\n",
      "Getting data for stanza: 09.046.04\n",
      "Getting data for stanza: 09.051.01\n",
      "Getting data for stanza: 09.055.04\n",
      "Getting data for stanza: 09.061.04\n",
      "Getting data for stanza: 09.062.29\n",
      "Getting data for stanza: 09.065.09\n",
      "Getting data for stanza: 09.065.28\n",
      "Getting data for stanza: 09.066.18\n",
      "Getting data for stanza: 09.067.22\n",
      "Getting data for stanza: 09.067.23\n",
      "Getting data for stanza: 09.067.24\n",
      "Getting data for stanza: 09.067.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for stanza: 09.067.26\n",
      "Getting data for stanza: 09.067.27\n",
      "Getting data for stanza: 09.067.31\n",
      "Getting data for stanza: 09.069.03\n",
      "Getting data for stanza: 09.070.06\n",
      "Getting data for stanza: 09.071.02\n",
      "Getting data for stanza: 09.078.01\n",
      "Getting data for stanza: 09.079.02\n",
      "Getting data for stanza: 09.083.04\n",
      "Getting data for stanza: 09.084.01\n",
      "Getting data for stanza: 09.086.16\n",
      "Getting data for stanza: 09.097.30\n",
      "Getting data for stanza: 09.097.41\n",
      "Getting data for stanza: 09.104.03\n",
      "Getting data for stanza: 09.106.03\n",
      "Getting data for stanza: 10.002.04\n",
      "Getting data for stanza: 10.006.03\n",
      "Getting data for stanza: 10.009.07\n",
      "Getting data for stanza: 10.013.03\n",
      "Getting data for stanza: 10.013.04\n",
      "Getting data for stanza: 10.015.06\n",
      "Getting data for stanza: 10.018.13\n",
      "Getting data for stanza: 10.021.01\n",
      "Getting data for stanza: 10.023.05\n",
      "Getting data for stanza: 10.025.03\n",
      "Getting data for stanza: 10.027.04\n",
      "Getting data for stanza: 10.027.13\n",
      "Getting data for stanza: 10.028.02\n",
      "Getting data for stanza: 10.030.05\n",
      "Getting data for stanza: 10.034.04\n",
      "Getting data for stanza: 10.035.01\n",
      "Getting data for stanza: 10.035.02\n",
      "Getting data for stanza: 10.036.02\n",
      "Getting data for stanza: 10.036.03\n",
      "Getting data for stanza: 10.036.04\n",
      "Getting data for stanza: 10.036.05\n",
      "Getting data for stanza: 10.036.06\n",
      "Getting data for stanza: 10.036.07\n",
      "Getting data for stanza: 10.036.08\n",
      "Getting data for stanza: 10.036.09\n",
      "Getting data for stanza: 10.036.10\n",
      "Getting data for stanza: 10.036.11\n",
      "Getting data for stanza: 10.036.12\n",
      "Getting data for stanza: 10.045.06\n",
      "Getting data for stanza: 10.047.08\n",
      "Getting data for stanza: 10.048.11\n",
      "Getting data for stanza: 10.055.01\n",
      "Getting data for stanza: 10.055.03\n",
      "Getting data for stanza: 10.061.03\n",
      "Getting data for stanza: 10.062.01\n",
      "Getting data for stanza: 10.062.02\n",
      "Getting data for stanza: 10.062.03\n",
      "Getting data for stanza: 10.062.04\n",
      "Getting data for stanza: 10.067.06\n",
      "Getting data for stanza: 10.067.12\n",
      "Getting data for stanza: 10.084.05\n",
      "Getting data for stanza: 10.085.03\n",
      "Getting data for stanza: 10.085.04\n",
      "Getting data for stanza: 10.085.14\n",
      "Getting data for stanza: 10.085.24\n",
      "Getting data for stanza: 10.085.36\n",
      "Getting data for stanza: 10.087.05\n",
      "Getting data for stanza: 10.087.10\n",
      "Getting data for stanza: 10.087.14\n",
      "Getting data for stanza: 10.087.25\n",
      "Getting data for stanza: 10.089.06\n",
      "Getting data for stanza: 10.089.08\n",
      "Getting data for stanza: 10.092.14\n",
      "Getting data for stanza: 10.095.05\n",
      "Getting data for stanza: 10.100.01\n",
      "Getting data for stanza: 10.100.02\n",
      "Getting data for stanza: 10.100.03\n",
      "Getting data for stanza: 10.100.04\n",
      "Getting data for stanza: 10.100.05\n",
      "Getting data for stanza: 10.100.06\n",
      "Getting data for stanza: 10.100.07\n",
      "Getting data for stanza: 10.100.08\n",
      "Getting data for stanza: 10.100.09\n",
      "Getting data for stanza: 10.100.10\n",
      "Getting data for stanza: 10.100.11\n",
      "Getting data for stanza: 10.101.07\n",
      "Getting data for stanza: 10.111.04\n",
      "Getting data for stanza: 10.113.04\n",
      "Getting data for stanza: 10.116.03\n",
      "Getting data for stanza: 10.117.05\n",
      "Getting data for stanza: 10.117.09\n",
      "Getting data for stanza: 10.120.01\n",
      "Getting data for stanza: 10.122.01\n",
      "Getting data for stanza: 10.126.02\n",
      "Getting data for stanza: 10.127.08\n",
      "Getting data for stanza: 10.134.07\n",
      "Getting data for stanza: 10.138.04\n",
      "Getting data for stanza: 10.139.05\n",
      "Getting data for stanza: 10.139.06\n",
      "Getting data for stanza: 10.145.04\n",
      "Getting data for stanza: 10.149.01\n",
      "Getting data for stanza: 10.153.03\n",
      "Getting data for stanza: 10.171.03\n"
     ]
    }
   ],
   "source": [
    "for stanza_no in rv_stanza_nos:\n",
    "    print(f\"Getting data for stanza: {stanza_no}\")\n",
    "    \n",
    "    # eg: https://vedaweb.uni-koeln.de/rigveda/api/document/id/0100102\n",
    "    vedaweb_doc_id = stanza_no.replace('.', '')\n",
    "    vedaweb_doc_url = f\"{VEDAWEB_API_URL}/document/id/{vedaweb_doc_id}\"\n",
    "    \n",
    "    response = requests.get(vedaweb_doc_url)\n",
    "    # raises an exception on non-200 responses, since we want to know and act on it\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with open(f\"downloads/vedaweb/{stanza_no}.json\", 'w') as f:\n",
    "        f.write(response.text)\n",
    "    \n",
    "    # so that we don't hammer the api\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e3213",
   "metadata": {},
   "source": [
    "### Enriching the lines with text and metrical info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "979e0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f726493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/roots_ninth_class_attestations.json\") as f:\n",
    "    roots_attested_words_by_stanza = json.load(f)\n",
    "    \n",
    "#print(roots_attested_words_by_stanza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9499e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attestation_texts': '',\n",
      " 'book': '01',\n",
      " 'hymn': '01.063',\n",
      " 'hymn_absolute_no': 63,\n",
      " 'hymn_addressee': 'Indra',\n",
      " 'hymn_group': 'Hymns of Nodhas, Descendant of Gotama',\n",
      " 'language_period': 'Earlier',\n",
      " 'line_no': '01.063.02.d',\n",
      " 'meter_scansion': 'SS LLS SSLS LL',\n",
      " 'pada_id': 'd',\n",
      " 'pada_label': 'M',\n",
      " 'root': 'iṣ 1',\n",
      " 'root_guess': 'iṣ',\n",
      " 'stanza': '01.063.02',\n",
      " 'stanza_late_addition': '',\n",
      " 'stanza_meter': 'Triṣṭubh',\n",
      " 'stanza_strata': 'A',\n",
      " 'stem': 'iṣṇā',\n",
      " 'stem_type': 'strong',\n",
      " 'text_padapatha': 'púraḥ iṣṇā́si= puruhūta pūrvī́ḥ',\n",
      " 'text_samhitapatha': 'púra iṣṇā́si puruhūta pūrvī́ḥ',\n",
      " 'variant_no': '',\n",
      " 'weak_only': False,\n",
      " 'word': 'iṣṇā́si',\n",
      " 'word_gloss': '2.SG.PRS.IND.ACT',\n",
      " 'word_position': 'intermediate',\n",
      " 'word_position_no': 2}\n",
      "\n",
      "Total number of lines: 347\n"
     ]
    }
   ],
   "source": [
    "def pada_char_to_no(char):\n",
    "    # TODO turn this into a dict\n",
    "    match char:\n",
    "        case 'a':\n",
    "            return 0\n",
    "        case 'b':\n",
    "            return 1\n",
    "        case 'c':\n",
    "            return 2\n",
    "        case 'd':\n",
    "            return 3\n",
    "        case 'e':\n",
    "            return 4\n",
    "        case 'f':\n",
    "            return 5\n",
    "        case 'g':\n",
    "            return 6\n",
    "        case _:\n",
    "            raise Exception(f\"Invalid pada char: {char}\")\n",
    "            \n",
    "            \n",
    "def get_stanza_words(stanza_padas):    \n",
    "    stanza_words = {}\n",
    "    \n",
    "    for pada_data in stanza_padas:\n",
    "        for word_grammar_data in pada_data[\"grammarData\"]:\n",
    "            word = word_grammar_data[\"form\"]\n",
    "            \n",
    "            word_grammar_data_props = word_grammar_data[\"props\"]\n",
    "            word_position = word_grammar_data_props.pop(\"position\", '')\n",
    "            word_lemma_type = word_grammar_data_props.pop(\"lemma type\", '')\n",
    "\n",
    "            word_data = {\n",
    "                # tracker for when we later search for the actual attested words\n",
    "                \"found\": False, \n",
    "                \"data\": {\n",
    "                    \"pada_id\": pada_data[\"id\"],\n",
    "                    # TODO test with this and later eliminate\n",
    "                    #\"pada_index\": pada_data[\"index\"], \n",
    "                    \"pada_label\": pada_data[\"label\"],\n",
    "                    \"word\": word,\n",
    "                    \"word_position_no\": word_grammar_data[\"index\"], # not-zero-indexed!\n",
    "                    # TODO be careful of this, does not seem to be accurate\n",
    "                    # (eg: for \"punīhi\" for 9.67.24 )\n",
    "                    # TODO use these for checks\n",
    "                    \"word_position\": word_position,\n",
    "                    \"word_lemma_type\": word_lemma_type,\n",
    "                    # FIXME pass this and use to validate further\n",
    "                    #\"word_lemma\": word_grammar_data[\"lemma\"]\n",
    "                    \"word_props\": word_grammar_data_props,\n",
    "                    # TODO this not needed since all of it is contained in props\n",
    "                    # but pass and validate they are the same...\n",
    "                    #\"word_gloss\": word_tracker_gloss\n",
    "                }\n",
    "            }\n",
    "                \n",
    "            if word in stanza_words:\n",
    "                stanza_words[word].append(word_data)\n",
    "            else:\n",
    "                # need to use a list since the word may appear multiple times in the stanza\n",
    "                stanza_words[word] = [word_data]\n",
    "    \n",
    "    return stanza_words\n",
    "    \n",
    "\n",
    "def get_words_by_pada(stanza_attested_words, stanza_padas, stanza_no=None):\n",
    "    words_by_pada = []\n",
    "    \n",
    "    #pprint(stanza_attested_words)\n",
    "    #pprint(stanza_padas)\n",
    "    \n",
    "    # transform data in stanza_padas to be amenable for searching the attested words\n",
    "    stanza_words = get_stanza_words(stanza_padas)\n",
    "    #pprint(stanza_words)\n",
    "    \n",
    "    for attested_word_data in stanza_attested_words:\n",
    "        attested_word = attested_word_data[\"word\"]\n",
    "        attested_word_gloss = attested_word_data[\"gloss\"]\n",
    "        \n",
    "        if attested_word in stanza_words:\n",
    "            for word_instance in stanza_words[attested_word]:\n",
    "                # if this word instance was already found, skip to the next one \n",
    "                if word_instance[\"found\"]:\n",
    "                    continue\n",
    "                    \n",
    "                word_instance_data = word_instance[\"data\"]\n",
    "                word_instance_lemma_type = word_instance_data.pop(\"word_lemma_type\")\n",
    "                \n",
    "                # FIXME check for lemma too?\n",
    "                # TODO also ensure this is not causing us to drop valid lines\n",
    "                if (word_instance_lemma_type and word_instance_lemma_type != \"root\"):\n",
    "                    print(\n",
    "                        f\"Skipping an instance of attested word {attested_word} because its lemma type\",\n",
    "                        f\"'{word_instance_lemma_type}' is not root\"\n",
    "                    )\n",
    "                    continue\n",
    "                    \n",
    "                if (word_instance_data[\"word_position\"] and\n",
    "                        \"position\" in attested_word_gloss and\n",
    "                        # python \"and\" operator is short-circuiting so can access \"position\" below\n",
    "                        # TODO can we trust this?\n",
    "                        word_instance_data[\"word_position\"] != attested_word_gloss[\"position\"]\n",
    "                    ):\n",
    "                    # even if we skip for a valid instance we will come back to it with a valid position later\n",
    "                    print(\n",
    "                        f\"Skipping an instance of attested word {attested_word} because it's position '{word_instance_data['word_position']}'\",\n",
    "                        f\"does not match the actual attested position '{attested_word_gloss['position']}'\"\n",
    "                    )\n",
    "                    continue                \n",
    "                \n",
    "                # TODO not needed since all of this info is already in word_instance_data\n",
    "                #word_instance_data[\"gloss\"] = attested_word_gloss\n",
    "                words_by_pada.append(word_instance_data)\n",
    "                \n",
    "                # no need to do this in-place for python!\n",
    "                word_instance[\"found\"] = True  \n",
    "                break\n",
    "        else:\n",
    "            # TODO handle this better? ok to let go maybe\n",
    "            raise Exception(\n",
    "                f\"Word {attested_word} was not found in the stanza {stanza_no}: {stanza_padas}\"\n",
    "            )    \n",
    "            \n",
    "    # something went wrong and we need to investigate\n",
    "    if len(words_by_pada) != len(stanza_attested_words):\n",
    "        raise Exception(\"No of word instances by pada does not match the input no of word instances attested in the stanza\")\n",
    "    \n",
    "    return words_by_pada            \n",
    "            \n",
    "      \n",
    "def annotate_line(line):    \n",
    "    with open(f\"downloads/vedaweb/{line['stanza']}.json\") as f:\n",
    "        stanza = json.load(f)\n",
    "        \n",
    "        # TODO get pada no for each line (could be multiple) using data in: \n",
    "        # roots_attested_words_by_stanza\n",
    "        # we will be ultimately returning multiple lines here sometimes\n",
    "        #if line[\"pada\"]:\n",
    "        #    pada_no = pada_char_to_no(line[\"pada\"][-1])\n",
    "        #    #pada_no = pada_char_to_no(line[\"pada_id\"])\n",
    "        #else:\n",
    "        \n",
    "        #pada_no = 0\n",
    "        \n",
    "        stanza_attested_words = roots_attested_words_by_stanza[line[\"root\"]][line[\"stem_type\"]][line[\"stanza\"]]\n",
    "            \n",
    "        words_by_pada = get_words_by_pada(stanza_attested_words, stanza[\"padas\"], line[\"stanza\"])\n",
    "        #pprint(words_by_pada)\n",
    "        \n",
    "        padas = []\n",
    "        \n",
    "        for word in words_by_pada:\n",
    "            pada = line | word\n",
    "            \n",
    "            # TODO rename line_no to location everywhere\n",
    "            pada[\"line_no\"] = pada[\"stanza\"] + \".\" + pada[\"pada_id\"]\n",
    "            # this is not needed now\n",
    "            pada.pop(\"pada\")\n",
    "            #pada[\"pada\"] = pada[\"stanza\"] + \".\" + pada[\"pada_id\"]\n",
    "            \n",
    "            # FIXME add each of these as a separate field too\n",
    "            word_props = pada.pop(\"word_props\")\n",
    "            pada[\"word_gloss\"] = f\"{word_props['person']}.{word_props['number']}\" + \\\n",
    "                f\".{word_props['tense']}.{word_props['mood']}.{word_props['voice']}\"\n",
    "            \n",
    "            # TODO try out getting index from stanza info directly and see if we still\n",
    "            # get the same results\n",
    "            pada_no = pada_char_to_no(pada[\"pada_id\"])\n",
    "            # TODO testing remove\n",
    "            #pada_no = 0\n",
    "\n",
    "            for version in stanza[\"versions\"]:\n",
    "                if version[\"id\"] == \"version_lubotsky\":\n",
    "                    pada[\"text_padapatha\"] = version[\"form\"][pada_no]\n",
    "                    break\n",
    "        \n",
    "            for version in stanza[\"versions\"]:\n",
    "                if version[\"id\"] == \"version_vannootenholland\":\n",
    "                    # TODO deal with * at the begining of the text here?\n",
    "                    pada[\"text_samhitapatha\"] = version[\"form\"][pada_no]\n",
    "                    pada[\"meter_scansion\"] = version[\"metricalData\"][pada_no]\n",
    "                    break\n",
    "            \n",
    "            pada[\"stanza_meter\"] = stanza[\"stanzaType\"] or ''\n",
    "    \n",
    "            # TODO get these info from hellewig too?\n",
    "            # historical info\n",
    "            pada[\"stanza_strata\"] = stanza[\"strata\"]\n",
    "            pada[\"stanza_late_addition\"] = stanza[\"lateAdditions\"] or ''\n",
    "            \n",
    "            # hymn extra metadata (maybe handy)\n",
    "            pada[\"hymn_absolute_no\"] = stanza[\"hymnAbs\"]\n",
    "            pada[\"hymn_addressee\"] = stanza[\"hymnAddressee\"]\n",
    "            pada[\"hymn_group\"] = stanza[\"hymnGroup\"]\n",
    "        \n",
    "            # this shouldn't really happen since the results we got were done\n",
    "            # via stem searches on the padapatha but validate, just in case\n",
    "            if not any([\n",
    "                stem_variant in pada[\"text_padapatha\"]\n",
    "                for stem_variant in pada[\"stem\"].split(\" \")\n",
    "            ]):\n",
    "                raise Exception(\n",
    "                    f'Stem {pada[\"stem\"]} not found in the padapatha text \"{pada[\"text_padapatha\"]}\"'\n",
    "                )   \n",
    "        \n",
    "            padas.append(pada)\n",
    "\n",
    "        return padas\n",
    "\n",
    "    \n",
    "#line_annotated = annotate_line(rv_lines[1])\n",
    "#pprint(line_annotated)\n",
    "\n",
    "#rv_lines_annotated = [annotate_line(line) for line in rv_lines]\n",
    "\n",
    "rv_lines_annotated = []\n",
    "for line in rv_lines:\n",
    "    # TODO rename the annotate function here\n",
    "    rv_lines_annotated.extend(annotate_line(line))\n",
    "\n",
    "pprint(rv_lines_annotated[0])\n",
    "print(f\"\\nTotal number of lines: {len(rv_lines_annotated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36e0993",
   "metadata": {},
   "source": [
    "### Saving the Final Line Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee56108d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_no</th>\n",
       "      <th>stem</th>\n",
       "      <th>stem_type</th>\n",
       "      <th>root_guess</th>\n",
       "      <th>variant_no</th>\n",
       "      <th>weak_only</th>\n",
       "      <th>attestation_texts</th>\n",
       "      <th>language_period</th>\n",
       "      <th>root</th>\n",
       "      <th>book</th>\n",
       "      <th>...</th>\n",
       "      <th>word_gloss</th>\n",
       "      <th>text_padapatha</th>\n",
       "      <th>text_samhitapatha</th>\n",
       "      <th>meter_scansion</th>\n",
       "      <th>stanza_meter</th>\n",
       "      <th>stanza_strata</th>\n",
       "      <th>stanza_late_addition</th>\n",
       "      <th>hymn_absolute_no</th>\n",
       "      <th>hymn_addressee</th>\n",
       "      <th>hymn_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.063.02.d</td>\n",
       "      <td>iṣṇā</td>\n",
       "      <td>strong</td>\n",
       "      <td>iṣ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>Earlier</td>\n",
       "      <td>iṣ 1</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.SG.PRS.IND.ACT</td>\n",
       "      <td>púraḥ iṣṇā́si= puruhūta pūrvī́ḥ</td>\n",
       "      <td>púra iṣṇā́si puruhūta pūrvī́ḥ</td>\n",
       "      <td>SS LLS SSLS LL</td>\n",
       "      <td>Triṣṭubh</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "      <td>63</td>\n",
       "      <td>Indra</td>\n",
       "      <td>Hymns of Nodhas, Descendant of Gotama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.063.04.b</td>\n",
       "      <td>ubhnā</td>\n",
       "      <td>strong</td>\n",
       "      <td>ubh</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>ubh</td>\n",
       "      <td>01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.SG.PRS.INJ.ACT</td>\n",
       "      <td>vr̥trám yát vajrin= vr̥ṣakarman ubhnā́ḥ</td>\n",
       "      <td>vr̥tráṁ yád vajrin vr̥ṣakarman ubhnā́ḥ</td>\n",
       "      <td>LL L LL SSLS LL</td>\n",
       "      <td>Triṣṭubh</td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "      <td>63</td>\n",
       "      <td>Indra</td>\n",
       "      <td>Hymns of Nodhas, Descendant of Gotama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04.019.04.c</td>\n",
       "      <td>ubhnā</td>\n",
       "      <td>strong</td>\n",
       "      <td>ubh</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>ubh</td>\n",
       "      <td>04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.SG.IPRF.IND.ACT</td>\n",
       "      <td>dr̥ḷhā́ni aubhnāt= uśámānaḥ ójaḥ</td>\n",
       "      <td>dr̥r̥ḷhā́ni+ aubhnād uśámāna ójo</td>\n",
       "      <td>SLLS LL SSLS LL</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td></td>\n",
       "      <td>315</td>\n",
       "      <td>Indra</td>\n",
       "      <td>Hymns to Indra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04.018.12.d</td>\n",
       "      <td>kṣiṇā</td>\n",
       "      <td>strong</td>\n",
       "      <td>kṣi</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>kṣī</td>\n",
       "      <td>04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.SG.IPRF.IND.ACT</td>\n",
       "      <td>yát prá ákṣiṇāḥ= pitáram pādagŕ̥hya</td>\n",
       "      <td>yát prā́kṣiṇāḥ pitáram pādagŕ̥hya</td>\n",
       "      <td>L LSL SSL LSLS</td>\n",
       "      <td>Triṣṭubh</td>\n",
       "      <td>P</td>\n",
       "      <td>[Grassmann (G), Arnold (C1)]</td>\n",
       "      <td>314</td>\n",
       "      <td>Dialogue Between Indra, Aditi and Vamadeva</td>\n",
       "      <td>Hymns to Indra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.027.04.d</td>\n",
       "      <td>kṣiṇā</td>\n",
       "      <td>strong</td>\n",
       "      <td>kṣi</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>kṣī</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.SG.PRS.INJ.ACT</td>\n",
       "      <td>prá tám kṣiṇām= párvate-_ pādagŕ̥hya</td>\n",
       "      <td>prá táṁ kṣiṇām párvate pādagŕ̥hya</td>\n",
       "      <td>S L SL LSL LSLS</td>\n",
       "      <td>Triṣṭubh</td>\n",
       "      <td>P</td>\n",
       "      <td>[Arnold (C1)]</td>\n",
       "      <td>853</td>\n",
       "      <td>Indra</td>\n",
       "      <td>The Vasukra Hymns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.027.13.c</td>\n",
       "      <td>kṣiṇā</td>\n",
       "      <td>strong</td>\n",
       "      <td>kṣi</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>kṣī</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.SG.PRS.IND.ACT</td>\n",
       "      <td>ā́sīnaḥ ūrdhvā́m= upási} kṣiṇāti</td>\n",
       "      <td>ā́sīna ūrdhvā́m upási kṣiṇāti</td>\n",
       "      <td>LLS LL SSL SLS</td>\n",
       "      <td>Triṣṭubh</td>\n",
       "      <td>P</td>\n",
       "      <td>[Arnold (C1)]</td>\n",
       "      <td>853</td>\n",
       "      <td>Indra</td>\n",
       "      <td>The Vasukra Hymns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09.046.04.b</td>\n",
       "      <td>gr̥bhṇī</td>\n",
       "      <td>weak</td>\n",
       "      <td>gr̥bh</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>gr̥bhⁱ</td>\n",
       "      <td>09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.PL.PRS.IND.ACT</td>\n",
       "      <td>śukrā́ gr̥bhṇīta manthínā</td>\n",
       "      <td>śukrā́ gr̥bhṇīta manthínā</td>\n",
       "      <td>LL LLS LSL</td>\n",
       "      <td>Gāyatrī</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>758</td>\n",
       "      <td>Soma</td>\n",
       "      <td>Tirasci and Other Poets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09.106.03.b</td>\n",
       "      <td>gr̥bhṇī</td>\n",
       "      <td>weak</td>\n",
       "      <td>gr̥bh</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>gr̥bhⁱ</td>\n",
       "      <td>09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.SG.PRS.INJ.MED</td>\n",
       "      <td>grābhám gr̥bhṇīta sānasím</td>\n",
       "      <td>grābháṁ gr̥bhṇīta sānasím</td>\n",
       "      <td>LL LLS LSL</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td></td>\n",
       "      <td>818</td>\n",
       "      <td>Soma</td>\n",
       "      <td>The Usnih Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.062.01.d</td>\n",
       "      <td>gr̥bhṇī</td>\n",
       "      <td>weak</td>\n",
       "      <td>gr̥bh</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>gr̥bhⁱ</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.PL.PRS.IND.ACT</td>\n",
       "      <td>práti gr̥bhṇīta= mānavám} sumedhasaḥ</td>\n",
       "      <td>práti gr̥bhṇīta mānaváṁ sumedhasaḥ</td>\n",
       "      <td>SS LLS LSL SLSL</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>[Arnold (C1)]</td>\n",
       "      <td>888</td>\n",
       "      <td>All the Gods or the Angiras, Thanksgiving to S...</td>\n",
       "      <td>Nabhanedistha Hymns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.062.02.d</td>\n",
       "      <td>gr̥bhṇī</td>\n",
       "      <td>weak</td>\n",
       "      <td>gr̥bh</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>V.B.</td>\n",
       "      <td>Earlier</td>\n",
       "      <td>gr̥bhⁱ</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.PL.PRS.IND.ACT</td>\n",
       "      <td>práti gr̥bhṇīta= mānavám} sumedhasaḥ</td>\n",
       "      <td>práti gr̥bhṇīta mānaváṁ sumedhasaḥ</td>\n",
       "      <td>SS LLS LSL SLSL</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>[Arnold (C1)]</td>\n",
       "      <td>888</td>\n",
       "      <td>All the Gods or the Angiras, Thanksgiving to S...</td>\n",
       "      <td>Nabhanedistha Hymns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       line_no     stem stem_type root_guess variant_no  weak_only  \\\n",
       "0  01.063.02.d     iṣṇā    strong         iṣ                 False   \n",
       "1  01.063.04.b    ubhnā    strong        ubh                 False   \n",
       "2  04.019.04.c    ubhnā    strong        ubh                 False   \n",
       "3  04.018.12.d    kṣiṇā    strong        kṣi                 False   \n",
       "4  10.027.04.d    kṣiṇā    strong        kṣi                 False   \n",
       "5  10.027.13.c    kṣiṇā    strong        kṣi                 False   \n",
       "6  09.046.04.b  gr̥bhṇī      weak      gr̥bh                 False   \n",
       "7  09.106.03.b  gr̥bhṇī      weak      gr̥bh                 False   \n",
       "8  10.062.01.d  gr̥bhṇī      weak      gr̥bh                 False   \n",
       "9  10.062.02.d  gr̥bhṇī      weak      gr̥bh                 False   \n",
       "\n",
       "  attestation_texts language_period    root book  ...         word_gloss  \\\n",
       "0                           Earlier    iṣ 1   01  ...   2.SG.PRS.IND.ACT   \n",
       "1                V.         Earlier     ubh   01  ...   3.SG.PRS.INJ.ACT   \n",
       "2                V.         Earlier     ubh   04  ...  3.SG.IPRF.IND.ACT   \n",
       "3              V.B.         Earlier     kṣī   04  ...  2.SG.IPRF.IND.ACT   \n",
       "4              V.B.         Earlier     kṣī   10  ...   1.SG.PRS.INJ.ACT   \n",
       "5              V.B.         Earlier     kṣī   10  ...   3.SG.PRS.IND.ACT   \n",
       "6              V.B.         Earlier  gr̥bhⁱ   09  ...   2.PL.PRS.IND.ACT   \n",
       "7              V.B.         Earlier  gr̥bhⁱ   09  ...   3.SG.PRS.INJ.MED   \n",
       "8              V.B.         Earlier  gr̥bhⁱ   10  ...   2.PL.PRS.IND.ACT   \n",
       "9              V.B.         Earlier  gr̥bhⁱ   10  ...   2.PL.PRS.IND.ACT   \n",
       "\n",
       "                            text_padapatha  \\\n",
       "0          púraḥ iṣṇā́si= puruhūta pūrvī́ḥ   \n",
       "1  vr̥trám yát vajrin= vr̥ṣakarman ubhnā́ḥ   \n",
       "2         dr̥ḷhā́ni aubhnāt= uśámānaḥ ójaḥ   \n",
       "3      yát prá ákṣiṇāḥ= pitáram pādagŕ̥hya   \n",
       "4     prá tám kṣiṇām= párvate-_ pādagŕ̥hya   \n",
       "5         ā́sīnaḥ ūrdhvā́m= upási} kṣiṇāti   \n",
       "6                śukrā́ gr̥bhṇīta manthínā   \n",
       "7                grābhám gr̥bhṇīta sānasím   \n",
       "8     práti gr̥bhṇīta= mānavám} sumedhasaḥ   \n",
       "9     práti gr̥bhṇīta= mānavám} sumedhasaḥ   \n",
       "\n",
       "                        text_samhitapatha   meter_scansion stanza_meter  \\\n",
       "0           púra iṣṇā́si puruhūta pūrvī́ḥ   SS LLS SSLS LL   Triṣṭubh   \n",
       "1  vr̥tráṁ yád vajrin vr̥ṣakarman ubhnā́ḥ  LL L LL SSLS LL   Triṣṭubh   \n",
       "2        dr̥r̥ḷhā́ni+ aubhnād uśámāna ójo  SLLS LL SSLS LL                \n",
       "3       yát prā́kṣiṇāḥ pitáram pādagŕ̥hya   L LSL SSL LSLS   Triṣṭubh   \n",
       "4       prá táṁ kṣiṇām párvate pādagŕ̥hya  S L SL LSL LSLS   Triṣṭubh   \n",
       "5           ā́sīna ūrdhvā́m upási kṣiṇāti   LLS LL SSL SLS   Triṣṭubh   \n",
       "6               śukrā́ gr̥bhṇīta manthínā       LL LLS LSL      Gāyatrī   \n",
       "7               grābháṁ gr̥bhṇīta sānasím       LL LLS LSL                \n",
       "8      práti gr̥bhṇīta mānaváṁ sumedhasaḥ  SS LLS LSL SLSL                \n",
       "9      práti gr̥bhṇīta mānaváṁ sumedhasaḥ  SS LLS LSL SLSL                \n",
       "\n",
       "   stanza_strata          stanza_late_addition hymn_absolute_no  \\\n",
       "0              A                                             63   \n",
       "1              A                                             63   \n",
       "2              S                                            315   \n",
       "3              P  [Grassmann (G), Arnold (C1)]              314   \n",
       "4              P                 [Arnold (C1)]              853   \n",
       "5              P                 [Arnold (C1)]              853   \n",
       "6              N                                            758   \n",
       "7              A                                            818   \n",
       "8              C                 [Arnold (C1)]              888   \n",
       "9              C                 [Arnold (C1)]              888   \n",
       "\n",
       "                                      hymn_addressee  \\\n",
       "0                                              Indra   \n",
       "1                                              Indra   \n",
       "2                                              Indra   \n",
       "3         Dialogue Between Indra, Aditi and Vamadeva   \n",
       "4                                              Indra   \n",
       "5                                              Indra   \n",
       "6                                               Soma   \n",
       "7                                               Soma   \n",
       "8  All the Gods or the Angiras, Thanksgiving to S...   \n",
       "9  All the Gods or the Angiras, Thanksgiving to S...   \n",
       "\n",
       "                              hymn_group  \n",
       "0  Hymns of Nodhas, Descendant of Gotama  \n",
       "1  Hymns of Nodhas, Descendant of Gotama  \n",
       "2                         Hymns to Indra  \n",
       "3                         Hymns to Indra  \n",
       "4                      The Vasukra Hymns  \n",
       "5                      The Vasukra Hymns  \n",
       "6                Tirasci and Other Poets  \n",
       "7                        The Usnih Group  \n",
       "8                    Nabhanedistha Hymns  \n",
       "9                    Nabhanedistha Hymns  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rv_lines = pandas.DataFrame.from_dict(rv_lines_annotated)\n",
    "df_rv_lines.to_csv(\"data/rv_lines_ninth_class.csv\", index=None)\n",
    "df_rv_lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756ec8b",
   "metadata": {},
   "source": [
    "## Validating the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52370525",
   "metadata": {},
   "source": [
    "### Checking for missing roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33b96723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c436c4a",
   "metadata": {},
   "source": [
    "Our starting list of roots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eba1286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 roots:\n",
      "['aś' 'aśⁱ' 'bandh' 'bhrī' 'dhu dhū' 'drū' 'dr̥' 'grath' 'gr̥' 'gr̥bhⁱ'\n",
      " 'gr̥hⁱ' 'gr̥̄ 1' 'hru' 'hr̥̄' 'i' 'iṣ 1' 'jyā' 'jñā' 'jū' 'kliś' 'krī'\n",
      " 'kuṣ' 'kṣī' 'lu' 'mathⁱ' 'mr̥d' 'mr̥̄ 1' 'muṣⁱ' 'mī 1' 'pruṣ' 'prī'\n",
      " 'pr̥̄ 1' 'puṣ' 'pū' 'ram' 'rī' 'skambhⁱ' 'spr̥' 'stambhⁱ' 'str̥̄' 'subh'\n",
      " 'sā si' 'ubh' 'uṣ' 'vli vlī' 'vr̥' 'vr̥ vr̥̄' 'śam' 'ścam' 'śrathⁱ' 'śrī'\n",
      " 'śrī 2' 'śr̥̄ 1']\n"
     ]
    }
   ],
   "source": [
    "roots_initial = np.sort(df_roots[\"root\"].unique())\n",
    "print(f\"{len(roots_initial)} roots:\\n{roots_initial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb5f14",
   "metadata": {},
   "source": [
    "Attested roots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b1f2654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 roots:\n",
      "['aśⁱ' 'bandh' 'gr̥bhⁱ' 'gr̥hⁱ' 'gr̥̄ 1' 'hr̥̄' 'iṣ 1' 'jyā' 'jñā' 'jū'\n",
      " 'krī' 'kṣī' 'mathⁱ' 'mr̥̄ 1' 'muṣⁱ' 'mī 1' 'prī' 'pr̥̄ 1' 'pū' 'ram' 'rī'\n",
      " 'skambhⁱ' 'stambhⁱ' 'str̥̄' 'sā si' 'ubh' 'vr̥ vr̥̄' 'śrathⁱ' 'śrī'\n",
      " 'śr̥̄ 1']\n"
     ]
    }
   ],
   "source": [
    "roots_present = np.sort(df_rv_lines[\"root\"].unique())\n",
    "print(f\"{len(roots_present)} roots:\\n{roots_present}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da8e86",
   "metadata": {},
   "source": [
    "Missing roots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8040fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 roots:\n",
      "['aś' 'bhrī' 'dhu dhū' 'drū' 'dr̥' 'grath' 'gr̥' 'hru' 'i' 'kliś' 'kuṣ'\n",
      " 'lu' 'mr̥d' 'pruṣ' 'puṣ' 'spr̥' 'subh' 'uṣ' 'vli vlī' 'vr̥' 'śam' 'ścam'\n",
      " 'śrī 2']\n"
     ]
    }
   ],
   "source": [
    "roots_absent = np.sort(\n",
    "    np.setdiff1d(df_roots[\"root\"].unique(), df_rv_lines[\"root\"].unique())\n",
    ")\n",
    "print(f\"{len(roots_absent)} roots:\\n{roots_absent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1c55c",
   "metadata": {},
   "source": [
    "TODO explain that these roots not being in RV is ok (and expected):\n",
    "    \n",
    "* Some roots are attested only as weak stem before vowel (i.e no _nī_ form). e.g.:  [_uṣ_](https://vedaweb.uni-koeln.de/rigveda/view/id/09.097.39)\n",
    "* Some roots are there in later vedic texts.\n",
    "* Some roots are already marked as later language in whitney (to be found only in Classical / Epic sanskrit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d22ff",
   "metadata": {},
   "source": [
    "TODO also try searching by alternate stem/root vowel forms for the missing roots (and also for the attested?), to see if there are actually recorded in those forms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79399395",
   "metadata": {},
   "source": [
    "### Checking found word against padapatha text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2945ea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09.104.03.a:1 (punā) punā́ta ≠ punā́tā [punā́tā+ dakṣasā́dhanam]\n",
      "02.033.13.c:3 (vr̥ṇī) ávr̥ṇīta ≠ ávr̥ṇītā [yā́ni mánuḥ= ávr̥ṇītā+} pitā́ naḥ]\n",
      "07.033.02.d:3 (vr̥ṇī) avr̥ṇīta ≠ avr̥ṇītā [sutā́t índraḥ= avr̥ṇītā+} vásiṣṭhān]\n",
      "\n",
      "Found 3 mismatches.\n"
     ]
    }
   ],
   "source": [
    "# from ./meter.py\n",
    "from meter import clean_lubotsky_padapatha\n",
    "\n",
    "mismatches = []\n",
    "\n",
    "no_of_mismatches = 0\n",
    "\n",
    "\n",
    "for line in rv_lines_annotated:\n",
    "    padapatha_text_cleaned = clean_lubotsky_padapatha(line[\"text_padapatha\"])\n",
    "    padapatha_parts = padapatha_text_cleaned.split(' ')\n",
    "    \n",
    "    word_from_padapatha = padapatha_parts[line[\"word_position_no\"] - 1]\n",
    "    \n",
    "    if line[\"word\"] != word_from_padapatha:\n",
    "        no_of_mismatches += 1\n",
    "        print(\n",
    "            f\"{line['line_no']}:{line['word_position_no']}\", \n",
    "            f\"({line['stem']}) {line['word']} ≠ {word_from_padapatha}\",\n",
    "            #f\"[{padapatha_text_cleaned}]\",\n",
    "            f\"[{line['text_padapatha']}]\"\n",
    "        )\n",
    "        \n",
    "print(f\"\\nFound {no_of_mismatches} mismatches.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59bf282",
   "metadata": {},
   "source": [
    "Ignore cases of final vowel lengthening above (especially with imperatives) -- they are not really mismatches.\n",
    "\n",
    "TODO look at vowel positions for these? but not really in the scope of our investigation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
